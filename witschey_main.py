from __future__ import division
import sys,collections,random

from functools import partial
from itertools import product
from models import *
from witschey.models import Model
from witschey.models import IndependentVariable as IV
from witschey.searchers import  DifferentialEvolution, ParticleSwarmOptimizer

class KNNModel(Model):

    def __init__(self, train, test, most):
        # the order of the independents and the cart_wrapper are coupled
        # and that's gross

        self.train, self.test, self.most = train, test, most

        independents = (
          IV(lo=1, hi=len(self.train), name='n_neighbors', gen_type=int),
          IV(valid_inputs=('euclidean', 'manhattan',
                           'chebyshev', 'minkowski',
                           # 'mahalanobis' 2d array only
                           ), name='metric'),
          IV(valid_inputs=('ball_tree', 'kd_tree', 'brute'),
                           name='algorithm'),
          # IV(valid_inputs=('uniform', 'distance'), name='weights'),
          IV(lo=1, hi=100, name='leaf_size', gen_type=int))

        super(KNNModel, self).__init__(
            independents=independents, dependents=(self.knn_wrapper,))

    # the order of the independets and this function parameters are
    # coupled
    # and that's gross
    def knn_wrapper(self, xs):
        from sklearn.neighbors import KNeighborsRegressor
        # n_neighbors, metric, algorithm, weights, leaf_size = xs
        n_neighbors, metric, algorithm, leaf_size = xs
        indep = map(lambda x: x[:self.most+1], self.train)
        dep   = map(lambda x: x[self.most+1],  self.train)
        r = KNeighborsRegressor(
          n_neighbors=n_neighbors,
          metric=metric,
          algorithm=algorithm,
          # weights=weights,
          leaf_size=leaf_size
          ).fit(indep,dep)
        return r.predict(self.test[:self.most+1])[0]

def run_de_knn(train, test, most, **kw):
  s = DifferentialEvolution(partial(KNNModel, train, test, most))
  result = s.run()
  return result.best


class CARTModel(Model):

    def __init__(self, train, test, most):
        # the order of the independents and the cart_wrapper are coupled
        # and that's gross

        self.train, self.test, self.most = train, test, most

        independents = (IV(lo=1, hi=100, name='min_samples_split', gen_type=int),
                        IV(lo=2, hi=200, name='max_leaf_nodes', gen_type=int))
          # IV(valid_inputs=('best', 'random'), name='splitter'),

        super(CARTModel, self).__init__(
            independents=independents, dependents=(self.cart_wrapper,))

    # the order of the independets and this function parameters are
    # coupled
    # and that's gross
    def cart_wrapper(self, xs):
        min_samples_split, max_leaf_nodes = xs
        # splitter, min_samples_split, max_leaf_nodes = xs

        # for x, arg in zip(self.xs, (splitter, min_samples_split, max_leaf_nodes)):
        for x, arg in zip(self.xs, (min_samples_split, max_leaf_nodes)):
            if not x.valid(arg):
                raise ModelInputException()

        return cart(self.train, self.test, self.most,
                    # splitter=splitter,
                    min_samples_split=min_samples_split,
                    max_leaf_nodes=max_leaf_nodes)

class RFModel(Model):

    def __init__(self, train, test, most):
        # the order of the independents and the cart_wrapper are coupled
        # and that's gross

        self.train, self.test, self.most = train, test, most

        independents = (IV(lo=1, hi=100, name='min_samples_split', gen_type=int),
                        IV(lo=2, hi=200, name='max_leaf_nodes', gen_type=int))

        super(RFModel, self).__init__(
            independents=independents, dependents=(self.forest_wrapper,))

    # the order of the independets and this function parameters are
    # coupled
    # and that's gross
    def forest_wrapper(self, xs):
        min_samples_split, max_leaf_nodes = xs

        return forest(self.train, self.test, self.most,
                      min_samples_split=min_samples_split,
                      max_leaf_nodes=max_leaf_nodes,
                      n_estimators=150)


class VerboseCARTModel(Model):

    def __init__(self, n, train, test, most):
        # the order of the independents and the cart_wrapper are coupled
        # and that's gross

        self.train, self.test, self.most = train, test, most

        independents = (IV(lo=1, hi=24, name='min_samples_split', gen_type=int),
                        IV(lo=2, hi=24, name='max_leaf_nodes', gen_type=int))

        super(VerboseCARTModel, self).__init__(
            independents=independents, dependents=(self.cart_wrapper,))

    # the order of the independets and this function parameters are
    # coupled
    # and that's gross
    def cart_wrapper(self, xs):
        min_samples_split, max_leaf_nodes = xs

        return verbose_cart(self.train, self.test, self.most,
                            min_samples_split=min_samples_split,
                            max_leaf_nodes=max_leaf_nodes)


def show_params(f):
  from functools import wraps

  @wraps(f)
  def wrapped(*args, **kwargs):
    # print args, kwargs
    return f(*args, **kwargs)

  return wrapped


def shuffle(lst):
  random.shuffle(lst)
  return lst

class Thing():
  id = -1
  def __init__(i,**fields) : 
    i.override(fields)
    i._id = Thing.id = Thing.id + 1
    i.finalize()
  def finalize(i): pass
  def override(i,d): i.__dict__.update(d); return i
  def plus(i,**d): i.override(d)
  def __repr__(i):
    d = i.__dict__
    name = i.__class__.__name__
    return name+'{'+' '.join([':%s %s' % (k,pretty(d[k])) 
                     for k in i.show()])+ '}'
  def show(i):
    return [k for k in sorted(i.__dict__.keys()) 
            if not k.startswith('_')]

def tunings( _ = None):
  return dict( 
    Flex= [5.07, 4.05, 3.04, 2.03, 1.01,    _],
    Pmat= [7.80, 6.24, 4.68, 3.12, 1.56,    _],
    Prec= [6.20, 4.96, 3.72, 2.48, 1.24,    _],
    Resl= [7.07, 5.65, 4.24, 2.83, 1.41,    _],
    Team= [5.48, 4.38, 3.29, 2.19, 1.01,    _], 
    acap= [1.42, 1.19, 1.00, 0.85, 0.71,    _], 
    aexp= [1.22, 1.10, 1.00, 0.88, 0.81,    _], 
    cplx= [0.73, 0.87, 1.00, 1.17, 1.34, 1.74], 
    data= [   _, 0.90, 1.00, 1.14, 1.28,    _], 
    docu= [0.81, 0.91, 1.00, 1.11, 1.23,    _],
    ltex= [1.20, 1.09, 1.00, 0.91, 0.84,    _], 
    pcap= [1.34, 1.15, 1.00, 0.88, 0.76,    _], 
    pcon= [1.29, 1.12, 1.00, 0.90, 0.81,    _], 
    plex= [1.19, 1.09, 1.00, 0.91, 0.85,    _], 
    pvol= [   _, 0.87, 1.00, 1.15, 1.30,    _], 
    rely= [0.82, 0.92, 1.00, 1.10, 1.26,    _], 
    ruse= [   _, 0.95, 1.00, 1.07, 1.15, 1.24], 
    sced= [1.43, 1.14, 1.00, 1.00, 1.00,    _], 
    site= [1.22, 1.09, 1.00, 0.93, 0.86, 0.80], 
    stor= [   _,    _, 1.00, 1.05, 1.17, 1.46], 
    time= [   _,    _, 1.00, 1.11, 1.29, 1.63], 
    tool= [1.17, 1.09, 1.00, 0.90, 0.78,    _])



Features=dict(Sf=[ 'Prec','Flex','Resl','Team','Pmat'],
              Prod=['rely','data','cplx','ruse','docu'],
              Platform=['time','stor','pvol'],
              Person=['acap','pcap','pcon','aexp','plex','ltex'],
              Project=['tool','site','sced'])

def options():
  return Thing(levels=10,samples=20,shrink=0.66,round=2,epsilon=0.00,
               guesses=1000)


Features=dict(Sf=[ 'Prec','Flex','Resl','Team','Pmat'],
              Prod=['rely','data','cplx','ruse','docu'],
              Platform=['time','stor','pvol'],
              Person=['acap','pcap','pcon','aexp','plex','ltex'],
              Project=['tool','site','sced'])

def has(x,lst):
 try:
   out=lst.index(x)
   return out
 except ValueError:
    return None



def isbsg10(opt=options(),tunings=tunings()):
  vl=1;l=2;n=3;h=4;vh=5;xh=6;_=0
  return Thing(
    kloc=10,
    effort=11,
    names = ['Data_Quality','UFP','IS','DP','LT','PPL','CA','FS','RS','Recording_Method','FPS','Effort'],
    projects=[
    [1,1,1,1,1,1,1,225,1,1,1,1856],
      [1,1,1,1,1,2,1,599,2,1,2,10083],
      [1,1,1,2,1,2,1,333,2,1,3,5208],
      [1,1,2,3,2,3,1,748,2,2,3,1518],
      [1,1,1,1,1,4,1,158,1,1,4,3376],
      [1,1,1,1,1,2,1,427,2,1,3,5170],
      [2,2,3,4,3,5,1,461,2,3,4,12149],
      [1,1,4,3,2,3,1,257,1,2,3,452],
      [1,1,1,2,3,6,1,115,1,1,4,441],
      [1,1,5,3,2,3,1,116,1,4,4,112],
      [1,1,1,2,1,7,1,323,2,1,3,1530],
      [1,1,1,2,1,1,1,134,1,1,3,1807],
      [1,1,1,2,1,14,1,292,1,1,3,1087],
      [2,2,4,4,1,8,1,399,2,3,3,7037],
      [1,1,1,1,1,2,1,44,3,1,4,784],
      [1,1,1,2,1,9,1,298,1,1,4,3268],
      [1,1,1,2,1,2,1,66,3,1,3,800],
      [1,1,6,3,2,3,1,243,1,2,4,257],
      [1,1,1,4,1,10,1,1105,4,1,5,14453],
      [1,1,4,3,2,3,1,679,2,4,4,326],
      [2,2,7,5,1,4,1,303,2,3,4,8490],
      [1,1,1,2,1,1,1,147,1,1,3,672],
      [1,1,7,3,2,3,1,143,1,2,3,98],
      [1,1,1,2,1,11,1,614,2,1,4,3280],
      [2,2,7,4,3,5,1,183,1,3,4,7327],
      [1,1,8,3,2,3,1,138,1,2,4,87],
      [1,1,1,2,3,12,1,129,1,1,3,1261],
      [1,1,1,2,1,2,1,205,1,1,3,3272],
      [1,1,1,2,1,1,1,471,2,1,3,1464],
      [1,1,1,5,1,4,1,97,3,1,3,1273],
      [1,1,3,3,2,3,1,1371,4,2,3,2274],
      [1,1,1,4,1,2,1,291,1,1,4,1772],
      [1,1,9,3,2,3,1,995,2,2,4,614],
      [1,2,4,2,3,6,2,211,1,3,4,1021],
      [2,2,10,2,3,13,2,192,1,3,4,1806],
      [2,2,10,2,3,13,2,98,3,3,4,921],
      [2,2,7,4,1,14,1,112,1,3,4,2134]
      ]
    )

def kemerer(opt=options(),tunings=tunings()):
  vl=1;l=2;n=3;h=4;vh=5;xh=6;_=0
  return Thing(
    kloc = 5,
    effort = 6,
    names = ['Language','Hardware','Duration','KSLOC','AdjFP','RAWFP','Effort'],
    projects = [
    [1,1,17,253.6,1217.1,1010,287],
        [1,2,7,40.5,507.3,457,82.5],
        [1,3,15,450,2306.8,2284,1107.31],
        [1,1,18,214.4,788.5,881,86.9],
        [1,2,13,449.9,1337.6,1583,336.3],
        [1,4,5,50,421.3,411,84],
        [2,4,5,43,99.9,97,23.2],
        [1,2,11,200,993,998,130.3],
        [1,1,14,289,1592.9,1554,116],
        [1,1,5,39,240,250,72],
        [1,1,13,254.2,1611,1603,258.7],
        [1,5,31,128.6,789,724,230.7],
        [1,6,20,161.4,690.9,705,157],
        [1,1,26,164.8,1347.5,1375,246.9],
        [3,1,14,60.2,1044.3,976,69.9]
    ]
  )

def cosmic(opt=options(),tunings=tunings()):
  vl=1;l=2;n=3;h=4;vh=5;xh=6;_=0
  return Thing(
  	kloc=9,
  	effort=10,
  	names = [    'Data_Quality','IS','OT','DT','DP','LT','PPL','FS','RS','FPS','Effort'],
  	projects=[
  	  [1,1,1,1,1,1,1,52,3,1,1188],
      [2,1,1,1,2,1,2,237,4,2,600],
      [2,2,2,1,3,2,3,1570,6,3,15233],
      [2,2,3,1,2,2,4,441,5,1,47493],
      [2,3,4,2,2,2,4,74,3,3,1597],
      [1,4,5,1,0,1,1,110,4,1,9234],
      [1,5,6,1,3,1,5,733,5,1,2950],
      [1,6,7,1,3,1,1,205,4,3,11165],
      [1,1,1,2,2,2,6,60,3,3,22444],
      [1,7,8,1,2,1,1,98,3,3,19306],
      [1,8,9,3,2,1,5,912,5,1,6590],
      [2,2,2,1,3,1,1,643,5,3,4224],
      [1,2,2,1,3,1,1,210,4,4,145],
      [2,2,2,1,3,1,1,61,3,2,669],
      [2,3,4,2,1,1,7,5,1,5,2410],
      [1,3,4,2,1,1,7,6,1,1,3563],
      [1,5,6,2,2,1,1,2003,6,1,536],
      [1,9,10,1,2,1,2,23,2,1,4847],
      [2,10,11,1,2,2,4,75,3,3,245],
      [1,11,12,2,2,1,1,746,5,3,3922],
      [2,11,13,2,1,1,7,90,3,1,724],
      [2,12,14,3,2,1,5,483,5,3,947],
      [1,12,15,1,2,1,1,177,4,3,451],
      [2,12,16,1,2,1,1,118,4,3,3638],
      [2,3,4,2,1,1,7,34,3,3,148],
      [1,6,17,1,2,1,5,1099,6,6,3167],
      [1,9,18,1,4,1,1,86,3,7,1184],
      [2,9,19,1,2,1,5,1958,6,8,2459],
      [1,11,13,2,2,1,1,14,2,1,12556],
      [1,13,20,2,3,1,9,51,3,1,1613],
      [2,12,21,3,2,1,1,791,5,3,3558],
      [2,4,22,2,3,2,8,5,1,2,784],
      [1,4,22,2,3,2,8,9,1,9,134],
      [1,4,22,2,3,2,8,3,1,1,3238],
      [1,4,22,2,3,2,8,2,1,1,3193],
      [1,4,22,2,3,2,8,2,1,10,40],
      [1,6,23,1,2,1,1,187,4,1,3069],
      [2,1,1,3,3,2,10,118,4,1,1488],
      [1,1,1,1,2,1,1,435,5,1,3401],
      [1,1,1,1,3,2,10,175,4,1,3306],
      [1,7,24,1,2,1,11,99,3,8,252],
      [2,9,25,2,2,1,5,82,3,3,840]
  	]
  	)
def china(opt=options(),tunings=tunings()):
  vl=1;l=2;n=3;h=4;vh=5;xh=6;_=0
  return Thing(
    sfem=15,
    kloc=16,
    effort=17,
    names =[
     'AFP','Input','Output','Enquiry','File','Interface','Added','Changed','Deleted',
     'PDR_AFP', 'PDR_UFP', 'NPDR_AFP', 'NPDU_UFP', 'Resource', 'Dev.Type', 'Duration',
    'effort','n_effort'],
    projects=[
     [1587,774,260,340,128,0,1502,0,0,4.7,5,4.7,5,4,0,4,7490,7490],
      [260,9,4,3,193,41,51,138,61,16,16.6,16,16.6,2,0,17,4150,4150],
      [152,25,33,28,42,35,163,0,0,4.4,4.1,4.4,4.1,1,0,9,668,668],
      [252,151,28,8,39,0,69,153,4,12.8,14.3,15.5,17.3,1,0,4,3238,3901],
      [292,93,0,194,20,0,0,307,0,10.3,9.8,12.4,11.7,1,0,13,2994,3607],
      [83,63,0,24,0,0,0,87,0,16.1,15.3,19.3,18.5,1,0,4,1333,1606],
      [79,24,0,23,30,0,0,77,0,20.3,20.9,24.5,25.1,1,0,6,1607,1936],
      [97,0,108,7,0,5,120,0,0,11.9,9.7,11.9,9.7,2,0,7,1158,1158],
      [116,0,23,58,14,20,81,34,0,10.7,10.8,12.9,13,1,0,6,1243,1498],
      [52,39,7,0,0,0,0,46,0,64.8,73.3,78.1,88.3,1,0,7,3372,4063],
      [465,209,129,24,83,15,460,0,0,21.9,22.2,21.9,22.2,1,0,9,10200,10200],
      [67,32,5,16,7,0,25,35,0,25.4,28.4,30.6,34.2,1,0,7,1704,2053],
      [199,0,115,57,0,42,214,0,0,13.3,12.3,15.2,14.2,2,0,7,2640,3034],
      [176,13,54,54,40,7,168,0,0,19,19.9,19,19.9,1,0,26,3348,3348],
      [391,208,26,81,25,0,38,302,0,1.7,2,2.1,2.4,1,0,7,676,814],
      [263,65,45,101,42,10,176,87,0,3.5,3.5,3.5,3.5,1,0,3,911,911],
      [42,12,15,3,7,15,52,0,0,59.4,48,59.4,48,1,0,6.4,2496,2496],
      [190,98,20,16,63,5,160,42,0,6.2,5.8,6.2,5.8,1,0,10,1171,1171],
      [245,105,28,18,58,0,19,190,0,14.4,16.9,14.4,16.9,1,0,13,3532,3532],
      [77,28,0,42,0,0,0,70,0,5.7,6.2,6.8,7.5,1,0,1,436,525],
      [355,278,0,73,0,0,0,351,0,2.6,2.6,3.1,3.1,1,0,4,909,1095],
      [3156,2075,525,97,0,0,28,12,2657,2.9,3.4,3.5,4.1,1,0,6,9094,10957],
      [46,0,28,0,25,0,28,25,0,7.5,6.5,7.5,6.5,1,0,6,344,344],
      [56,14,12,15,7,5,53,0,0,5.3,5.6,5.3,5.6,4,0,3,296,296],
      [106,65,4,12,14,0,35,53,7,33,36.9,39.8,44.4,1,0,13,3503,4220],
      [71,31,28,9,7,0,31,23,21,3.5,3.3,4.2,3.9,1,0,1,246,296],
      [306,51,105,0,105,45,306,0,0,6.8,6.8,6.8,6.8,2,0,24,2082,2082],
      [244,68,78,22,62,14,244,0,0,0.8,0.8,0.8,0.8,4,0,7,191,191],
      [98,21,46,3,44,0,114,0,0,30.3,26.1,36.6,31.4,1,0,15,2974,3583],
      [331,100,44,61,107,0,312,0,0,1,1.1,1.2,1.3,1,0,2,328,395],
      [101,16,5,39,52,0,112,0,0,4,3.6,4,3.6,1,0,8,406,406],
      [192,9,102,0,10,77,198,0,0,9.3,9,11.2,10.9,1,0,8,1785,2151],
      [60,39,4,0,14,10,39,22,6,7.9,7,7.9,7,2,0,8,471,471],
      [180,74,18,33,57,0,153,29,0,3.9,3.8,3.9,3.8,2,0,5,700,700],
      [118,43,71,7,0,0,38,83,0,4.9,4.8,5.9,5.8,1,0,2,579,698],
      [73,43,10,4,15,0,6,66,0,16.6,16.8,20,20.3,1,0,3,1211,1459],
      [143,63,0,27,45,0,14,121,0,8,8.4,9.6,10.2,1,0,4,1139,1372],
      [2190,706,648,236,235,0,1825,0,0,6.6,8,7.6,9.1,2,0,19,14520,16690],
      [9,0,10,0,0,0,5,5,0,26.6,23.9,26.6,23.9,1,0,2,239,239],
      [203,21,167,3,10,0,201,0,0,6.2,6.3,7.5,7.6,1,0,5,1262,1520],
      [162,64,36,9,28,20,157,0,0,10.8,11.2,10.8,11.2,1,0,8,1754,1754],
      [183,60,21,29,71,0,181,0,0,8.3,8.4,10,10.1,1,0,6,1514,1824],
      [59,36,21,0,0,0,6,51,0,11.3,11.7,13.6,14.1,1,0,8,667,804],
      [412,198,14,99,91,10,412,0,0,14.2,14.2,14.2,14.2,1,0,20,5864,5864],
      [348,198,14,33,77,0,10,312,0,2.8,3,3.4,3.6,1,0,3,973,1172],
      [2529,554,513,66,703,220,2056,0,0,2.1,2.6,2.1,2.6,2,0,13,5333,5333],
      [250,28,92,57,0,30,164,43,0,7.1,8.6,7.1,8.6,2,0,8,1775,1775],
      [206,0,199,0,0,5,100,104,0,1,1,1.2,1.2,1,0,5,204,246],
      [617,184,136,103,133,0,377,179,0,5.1,5.7,6.1,6.8,1,0,7,3148,3793],
      [173,0,78,10,17,72,177,0,0,50.4,49.2,60.7,59.3,1,0,12,8716,10501],
      [286,45,156,27,37,0,265,0,0,5.1,5.5,5.1,5.5,1,0,6,1464,1464],
      [52,13,17,6,10,5,20,16,15,26.1,26.6,31.5,32.1,1,0,2,1358,1636],
      [45,6,28,0,0,25,59,0,0,6.2,4.8,6.2,4.8,2,0,7,281,281],
      [104,30,7,48,15,0,0,100,0,22.3,23.2,26.9,28,1,0,5,2321,2796],
      [465,234,44,104,118,0,431,15,54,8.7,8.1,10.5,9.8,1,0,13,4054,4884],
      [2145,862,63,491,518,300,2234,0,0,1.1,1.1,1.1,1.1,4,0,84,2400,2400],
      [283,20,125,39,91,17,292,0,0,20,19.3,20,19.3,1,0,13,5650,5650],
      [109,0,84,0,17,5,47,59,0,14,14.4,16.9,17.3,1,0,2,1525,1837],
      [160,0,21,72,25,40,74,68,16,3,3,3.6,3.6,1,0,2,477,575],
      [65,0,64,0,0,0,54,10,0,7.7,7.9,9.3,9.5,1,0,2,503,606],
      [366,160,27,96,72,0,260,84,11,23.1,23.9,27.9,28.7,1,0,10,8470,10205],
      [63,18,10,3,28,0,16,43,0,12.3,13.2,14.9,15.9,1,0,3,778,937],
      [309,126,13,59,153,30,381,0,0,8.4,6.8,8.4,6.8,4,0,7.5,2597,2597],
      [610,137,174,117,147,0,575,0,0,1.6,1.7,1.6,1.7,1,0,3,950,950],
      [562,165,125,93,119,0,502,0,0,10.2,11.4,10.2,11.4,3,0,13,5727,5727],
      [156,21,38,39,7,41,146,0,0,13.1,14,15.8,16.8,1,0,4,2040,2458],
      [75,30,5,19,21,0,40,35,0,49,49,59.1,59.1,1,0,8,3677,4430],
      [136,42,64,0,21,0,0,127,0,4.2,4.5,5.1,5.4,1,0,2,570,687],
      [96,13,56,0,10,40,119,0,0,12.7,10.3,47.2,38.1,2,0,8,1223,4530],
      [78,24,24,9,21,0,78,0,0,12.5,12.5,13.9,13.9,1,0,4,976,1084],
      [51,42,0,14,0,0,20,36,0,7.6,6.9,9.1,8.3,1,0,12,387,466],
      [1092,356,84,170,669,21,1300,0,0,4,3.4,4.9,4.1,1,0,13,4416,5320],
      [134,42,11,32,35,14,134,0,0,2.1,2.1,2.6,2.6,1,0,8,286,345],
      [75,24,9,0,36,0,0,69,0,4.1,4.4,4.9,5.3,1,0,5,305,367],
      [88,18,20,0,43,0,36,45,0,1.5,1.6,1.8,1.9,1,0,7,129,155],
      [3088,1061,1009,772,241,5,544,2544,0,1.4,1.4,1.4,1.4,1,0,8,4266,4266],
      [82,25,46,0,14,15,100,0,0,5.4,4.4,5.4,4.4,1,0,3,440,440],
      [110,30,66,0,7,0,18,85,0,12.4,13.2,12.4,13.2,1,0,2,1362,1362],
      [308,153,83,0,112,10,236,122,0,8.2,7.1,8.2,7.1,2,0,6,2533,2533],
      [143,75,32,3,62,0,172,0,0,1.6,1.3,1.6,1.3,1,0,10,225,225],
      [826,292,326,155,32,0,396,139,270,13.4,13.7,13.4,13.7,1,0,13,11045,11045],
      [3460,484,1831,318,208,142,2756,227,0,9.5,11,9.5,11,4,0,24,32760,32760],
      [73,15,32,0,28,5,80,0,0,28.1,25.7,33.9,30.9,1,0,8,2054,2475],
      [64,4,56,0,7,0,11,56,0,3.9,3.8,3.9,3.8,1,0,7,252,252],
      [497,122,28,113,273,10,454,92,0,4.8,4.3,4.8,4.3,2,0,8,2362,2362],
      [288,201,0,36,76,0,99,214,0,8.5,7.9,10.3,9.5,1,0,5,2459,2963],
      [494,134,62,140,91,67,494,0,0,17.6,17.6,17.6,17.6,1,0,21,8706,8706],
      [130,60,65,0,0,0,14,111,0,5.9,6.2,5.9,6.2,1,0,6,770,770],
      [204,47,43,6,29,104,229,0,0,39.8,35.4,39.8,35.4,1,0,36,8111,8111],
      [17,12,5,0,0,0,17,0,0,44.8,44.8,44.8,44.8,1,0,11,762,762],
      [60,10,25,0,31,5,71,0,0,2.3,1.9,2.7,2.3,1,0,1,136,164],
      [73,0,20,36,10,0,56,10,0,4.9,5.4,5.9,6.5,1,0,1,358,431],
      [169,32,14,25,28,70,169,0,0,2.8,2.8,3.4,3.4,1,0,6,481,580],
      [1351,379,449,271,219,20,1173,29,136,2.4,2.4,2.8,2.9,1,0,8,3189,3842],
      [2087,862,444,303,437,0,2046,0,0,10.8,11,10.8,11,4,0,9,22500,22500],
      [253,72,0,107,29,44,252,0,0,46.3,46.3,49.8,49.8,1,0,13,11719,12601],
      [102,37,26,10,29,0,102,0,0,1.8,1.8,2.4,2.4,1,0,5,183,244],
      [115,49,39,0,15,0,53,50,0,12.9,14.4,15.5,17.3,1,0,5,1482,1786],
      [288,18,186,21,15,60,300,0,0,4.3,4.2,4.3,4.2,2,0,11,1251,1251],
      [199,104,7,77,0,0,0,188,0,4.7,5,5.7,6,1,0,8,943,1136],
      [163,49,14,33,49,10,155,0,0,16.5,17.3,19.8,20.9,1,0,11,2684,3234],
      [97,21,41,0,49,15,16,100,10,7.5,5.8,7.5,5.8,2,0,9,729,729],
      [439,82,222,19,85,10,105,313,0,8.3,8.7,8.3,8.7,1,0,7,3630,3630],
      [3113,2019,609,248,157,80,3113,0,0,10.9,10.9,13.5,13.5,1,0,24,34085,42080],
      [153,35,7,57,24,20,143,0,0,18.7,20,21.5,23,2,0,3,2856,3283],
      [670,346,97,122,79,0,146,498,0,8.6,8.9,10.4,10.8,1,0,6,5757,6936],
      [129,19,93,3,10,30,0,155,0,4.9,4.1,4.9,4.1,2,0,15,631,631],
      [329,324,68,14,0,0,206,73,127,6.6,5.4,6.6,5.4,2,0,8,2184,2184],
      [5684,2221,454,820,1137,311,4943,0,0,3.7,4.3,3.7,4.3,1,0,37,21014,21014],
      [61,27,4,24,17,0,72,0,0,6.8,5.8,8.2,7,1,0,4,417,502],
      [267,27,133,51,34,89,70,178,86,10,8,10,8,2,0,9,2683,2683],
      [218,78,16,56,77,0,227,0,0,25.4,24.4,30.6,29.4,1,0,4,5532,6665],
      [919,458,236,56,58,76,884,0,0,5.2,5.4,6.3,6.6,1,0,6,4815,5801],
      [66,27,12,6,14,0,28,31,0,3.7,4.2,4.5,5,1,0,2,246,296],
      [54,36,0,16,0,0,0,52,0,12.7,13.2,15.3,15.9,1,0,1,686,827],
      [245,88,105,27,79,0,299,0,0,1.9,1.6,3.6,2.9,1,0,13,470,870],
      [54,24,28,0,0,0,0,52,0,7.3,7.6,8.8,9.2,1,0,2,395,476],
      [151,40,54,15,21,0,111,19,0,7.2,8.3,8.2,9.5,2,0,3,1080,1241],
      [103,45,4,27,29,0,105,0,0,13.6,13.3,13.6,13.3,2,0,7,1396,1396],
      [300,95,82,27,76,0,138,142,0,9.8,10.5,9.8,10.5,1,0,10,2933,2933],
      [249,126,4,98,21,0,58,191,0,18.3,18.3,18.3,18.3,1,0,9,4551,4551],
      [224,156,21,0,29,10,6,210,0,13.4,13.9,16.1,16.7,1,0,4,2999,3613],
      [1984,255,1008,192,158,0,1613,0,0,1.3,1.6,1.3,1.6,2,0,11,2540,2540],
      [58,15,37,0,0,5,0,57,0,0.4,0.5,0.5,0.5,1,0,2,26,31],
      [56,50,0,3,0,0,0,53,0,8,8.5,9.6,10.2,1,0,2,448,540],
      [244,91,12,44,60,50,257,0,0,3.7,3.5,4.5,4.2,1,0,3,906,1092],
      [12,0,0,6,7,0,10,3,0,17.6,16.2,17.6,16.2,2,0,13,211,211],
      [1416,402,432,0,252,65,376,775,0,1.2,1.5,1.2,1.5,2,0,12,1724,1724],
      [67,3,26,0,7,35,71,0,0,23.6,22.3,27.2,25.6,2,0,5,1584,1821],
      [95,36,0,32,24,0,0,92,0,1.6,1.6,1.9,1.9,1,0,7,148,178],
      [2376,638,233,639,580,131,2221,0,0,10.7,11.5,12.9,13.8,1,0,24,25482,30701],
      [442,225,102,57,91,0,82,393,0,1.5,1.4,1.5,1.4,1,0,5,683,683],
      [68,21,12,19,15,0,11,56,0,37.1,37.6,44.7,45.3,1,0,4,2521,3037],
      [268,76,96,45,41,10,248,20,0,10.9,10.9,10.9,10.9,2,0,9,2933,2933],
      [90,96,0,0,0,0,96,0,0,5.5,5.1,6.6,6.2,1,0,2,494,595],
      [72,23,25,7,17,0,55,17,0,6.8,6.8,6.8,6.8,1,0,7,486,486],
      [505,111,127,18,216,0,472,0,0,9.8,10.5,9.8,10.5,1,0,30,4955,4955],
      [450,112,145,59,105,0,356,58,7,13.6,14.6,13.6,14.6,1,0,7,6138,6138],
      [230,129,38,46,57,0,230,40,0,6.3,5.4,7.6,6.5,1,0,10,1451,1748],
      [242,97,78,4,43,0,0,222,0,1.3,1.4,1.5,1.7,1,0,2,311,375],
      [106,21,76,6,0,0,7,96,0,23.1,23.7,27.8,28.6,1,0,2,2445,2946],
      [31,10,14,0,7,0,4,27,0,7.6,7.6,7.6,7.6,1,0,6,237,237],
      [1186,422,306,109,168,230,1235,0,0,3.1,3,3.1,3,3,0,9,3711,3711],
      [256,69,198,0,0,5,272,0,0,11.5,10.8,11.5,10.8,2,0,19,2941,2941],
      [191,44,60,15,49,25,159,34,0,12.7,12.6,12.7,12.6,2,0,11,2430,2430],
      [213,102,63,6,28,0,186,13,0,11.9,12.7,14.3,15.3,1,0,10,2532,3051],
      [4562,1098,1278,498,1059,0,3933,0,0,5.8,6.7,5.8,6.7,1,0,15,26408,26408],
      [141,44,33,44,17,0,5,133,0,8.8,9,10.6,10.9,1,0,2,1244,1499],
      [187,23,65,17,91,5,201,0,0,3,2.8,3.6,3.4,1,0,6,562,677],
      [128,45,0,68,0,15,128,0,0,25.8,25.8,56.1,56.1,1,0,10,3303,7180],
      [194,70,16,0,45,47,46,132,0,2.6,2.8,3.6,3.9,1,0,12,499,703],
      [869,288,300,116,230,0,934,0,0,2.4,2.2,2.4,2.2,3,0,6,2078,2078],
      [125,51,9,33,22,0,20,84,11,18.6,20.2,22.4,24.4,1,0,3,2326,2802],
      [477,235,117,89,46,10,172,218,107,5.7,5.5,5.7,5.5,1,0,6,2741,2741],
      [717,716,13,10,24,0,51,712,0,4.9,4.6,6,5.6,1,0,5,3546,4272],
      [25,0,28,0,0,0,0,28,0,5.6,5,5.6,5,1,0,3,140,140],
      [73,9,61,3,0,0,73,0,0,19.2,19.2,19.2,19.2,1,0,8,1404,1404],
      [100,61,0,0,0,42,28,75,0,9.3,9,11.2,10.9,1,0,12,929,1119],
      [273,103,183,15,17,0,318,0,0,1.9,1.7,1.9,1.7,3,0,5,528,528],
      [587,108,119,94,203,0,524,0,0,6.4,7.2,6.4,7.2,3,0,15,3748,3748],
      [1437,920,154,41,203,0,1318,0,0,3.4,3.7,3.4,3.7,4,0,18,4900,4900],
      [97,3,101,3,0,7,108,6,0,19.1,16.3,19.1,16.3,2,0,12,1853,1853],
      [224,110,25,6,49,5,195,0,0,12.9,14.8,14.8,17,2,0,13,2890,3322],
      [321,168,46,9,77,15,315,0,0,3.4,3.4,3.4,3.4,4,0,11,1076,1076],
      [99,6,4,19,59,10,98,0,0,24.1,24.4,29.1,29.3,1,0,4,2387,2876],
      [416,179,40,54,109,7,318,65,6,3.8,4.1,4.6,4.9,1,0,6,1586,1911],
      [71,21,21,4,14,5,25,40,0,14,15.3,16.9,18.5,1,0,4,997,1201],
      [120,60,48,12,0,0,12,108,0,1.8,1.8,1.8,1.8,1,0,5,212,212],
      [213,72,43,3,84,30,132,97,3,6,5.5,6,5.5,2,0,12,1278,1278],
      [1634,625,387,223,399,0,1634,0,0,4.3,4.3,4.3,4.3,2,0,12,7060,7060],
      [275,184,11,48,7,0,7,243,0,2.6,2.8,2.6,2.8,1,0,9,702,702],
      [458,202,66,75,115,0,458,0,0,2,2,2,2,1,0,16,903,903],
      [218,28,118,44,0,10,91,109,0,31,33.8,37.4,40.8,1,0,8,6765,8151],
      [498,107,132,7,77,122,445,0,0,16.5,18.5,16.5,18.5,3,0,19,8227,8227],
      [143,54,65,0,14,0,11,122,0,2.3,2.5,2.8,3,1,0,4,334,402],
      [722,163,0,202,237,20,622,0,0,5.8,6.7,5.8,6.7,1,0,9,4164,4164],
      [236,27,192,12,37,0,268,0,0,29,25.5,29,25.5,2,0,15,6844,6844],
      [239,39,70,18,62,55,244,0,0,6.9,6.8,6.9,6.8,2,0,10,1661,1661],
      [1882,711,589,218,442,0,1960,0,0,3.2,3.1,3.2,3.1,2,0,10,6068,6068],
      [291,188,29,0,69,37,323,0,0,20.8,18.8,22.4,20.2,2,0,14,6063,6519],
      [328,124,71,61,66,0,322,0,0,2,2.1,2,2.1,1,0,13,665,665],
      [264,126,7,50,84,0,267,0,0,2.1,2,2.1,2,1,0,6,544,544],
      [270,54,42,53,91,30,270,0,0,3.3,3.3,3.3,3.3,1,0,6,893,893],
      [32,0,7,12,0,10,29,0,0,11,12.1,11,12.1,1,0,2.5,352,352],
      [1382,353,245,7,581,253,1439,0,0,2.4,2.3,2.4,2.3,4,0,8,3344,3344],
      [98,45,5,19,28,0,94,3,0,4.1,4.2,5,5,1,0,1,404,487],
      [289,3,100,0,66,145,314,0,0,19.8,18.3,19.8,18.3,2,0,8,5732,5732],
      [1059,299,234,144,217,60,954,0,0,21.6,24,24.9,27.6,2,0,17,22920,26345],
      [724,331,12,189,164,0,530,142,24,13,13.5,15.7,16.3,1,0,9,9409,11336],
      [40,10,22,0,17,0,49,0,0,7.1,5.8,7.1,5.8,4,0,4,285,285],
      [128,72,18,24,7,0,4,117,0,10.1,10.7,12.2,12.9,1,0,3,1293,1558],
      [1248,249,262,146,423,15,1095,0,0,12.2,13.8,12.2,13.8,4,0,12,15165,15165],
      [387,109,118,67,90,7,391,0,0,8.5,8.4,10.2,10.1,1,0,17,3287,3960],
      [73,0,65,0,0,5,19,44,7,10.5,10.9,12.6,13.1,1,0,3,764,920],
      [151,22,0,68,47,0,32,105,0,14.5,16,17.5,19.3,1,0,3,2194,2643],
      [465,48,162,0,196,37,443,0,0,4.3,4.5,5.2,5.5,1,0,4,2014,2427],
      [63,29,0,9,24,0,62,0,0,13.1,13.3,15.8,16.1,1,0,4,827,996],
      [226,88,70,19,28,0,92,106,7,11.1,12.2,11.1,12.2,1,0,10,2508,2508],
      [115,76,11,28,0,0,10,105,0,1.7,1.7,1.7,1.7,1,0,1.5,201,201],
      [189,39,112,3,28,0,0,182,0,3,3.1,3,3.1,2,0,15,563,563],
      [55,52,0,6,0,0,58,0,0,9.7,9.2,11.7,11.1,1,0,11,534,643],
      [85,12,44,0,24,0,12,68,0,12.2,13,14.7,15.7,1,0,4,1039,1252],
      [2143,219,657,3,485,437,1801,0,0,20.2,24,24.3,29,1,0,7,43303,52172],
      [520,181,160,9,55,25,430,0,0,6,7.3,6,7.3,2,0,8,3133,3133],
      [113,25,34,16,27,0,38,64,0,15.9,17.7,18.3,20.3,2,0,3,1801,2070],
      [264,85,17,26,133,0,157,98,6,10,10.1,12,12.2,1,0,6,2639,3180],
      [349,162,24,18,112,30,342,4,0,6.8,6.8,6.8,6.8,2,0,4,2360,2360],
      [229,88,5,0,17,131,241,0,0,11,10.5,12.7,12,2,0,5,2520,2897],
      [172,88,40,4,30,7,169,0,0,10.4,10.6,10.4,10.6,4,0,5,1788,1788],
      [323,108,57,53,74,31,323,0,0,3.8,3.8,3.8,3.8,1,0,13,1238,1238],
      [89,15,28,17,7,30,24,73,0,5,4.6,5,4.6,2,0,4,442,442],
      [878,113,404,161,133,17,828,0,0,3.8,4.1,4.3,4.5,1,0,5,3368,3742],
      [220,81,50,51,42,0,224,0,0,1.3,1.3,1.3,1.3,3,0,3,281,281],
      [150,125,4,20,0,0,6,143,0,4.6,4.6,5.5,5.6,1,0,3,687,828],
      [161,60,38,30,41,0,169,0,0,1.4,1.3,1.4,1.3,1,0,2,220,220],
      [804,345,334,0,236,42,957,0,0,14.2,11.9,17.1,14.3,1,0,12,11388,13720],
      [272,63,20,61,71,30,245,0,0,35.7,39.7,41.1,45.6,2,0,14,9720,11172],
      [33,8,7,0,10,15,32,8,0,4.4,3.6,4.4,3.6,2,0,2,145,145],
      [64,20,28,10,7,0,65,0,0,2.2,2.2,2.2,2.2,2,0,3,140,140],
      [277,48,110,47,49,0,84,170,0,4.6,5,4.6,5,2,0,19,1265,1265],
      [322,78,100,67,54,0,179,106,14,16.3,17.5,19.6,21.1,1,0,13,5242,6316],
      [164,52,56,18,7,20,110,43,0,17,18.2,17,18.2,2,0,11,2791,2791],
      [145,48,10,72,14,0,144,0,0,5.1,5.2,6.2,6.2,1,0,3,742,894],
      [73,36,24,12,0,0,0,72,0,8,8.1,9.6,9.8,1,0,5,584,704],
      [245,42,179,24,42,15,302,0,0,3.6,3,3.6,3,2,0,7,893,893],
      [406,209,36,125,20,0,102,288,0,13.9,14.5,16.7,17.4,1,0,7,5639,6794],
      [98,35,0,41,20,0,28,68,0,56.5,57.6,68,69.4,1,0,5,5533,6666],
      [83,44,10,3,25,0,15,63,4,4.9,5,6,6,1,0,3,410,494],
      [182,30,59,39,29,0,0,157,0,5.5,6.4,6.6,7.7,1,0,5,1001,1206],
      [820,460,98,199,175,0,685,212,35,3.1,2.7,3.1,2.7,4,0,11,2552,2552],
      [545,116,226,131,72,0,79,466,0,16,16,16,16,1,0,11,8740,8740],
      [105,96,9,0,0,0,21,84,0,1.9,1.9,1.9,1.9,1,0,8,198,198],
      [55,12,10,14,15,0,9,42,0,42.7,46,51.4,55.5,1,0,1,2347,2828],
      [62,27,4,0,31,7,69,0,0,13.2,11.8,15.9,14.3,1,0,8,817,984],
      [109,0,105,0,0,0,0,105,0,2.3,2.4,2.8,2.9,1,0,1,249,300],
      [436,27,334,15,0,60,436,0,0,17.8,17.8,17.8,17.8,2,0,15,7762,7762],
      [179,60,44,6,38,40,188,0,0,4.3,4.1,5.2,5,1,0,4,776,935],
      [1710,932,521,233,214,0,1900,0,0,7.7,6.9,7.7,6.9,2,0,21,13130,13130],
      [128,49,15,25,31,0,120,0,0,12.8,13.7,14.8,15.8,2,0,2,1644,1890],
      [174,21,7,30,50,32,140,0,0,77.7,96.6,77.7,96.6,4,0,8,13528,13528],
      [70,28,4,15,21,0,39,29,0,8.8,9.1,10.6,10.9,1,0,5,617,743],
      [379,159,29,57,119,15,379,0,0,6.3,6.3,6.3,6.3,1,0,7,2391,2391],
      [258,12,16,230,0,0,26,232,0,2.3,2.3,2.3,2.3,2,0,5,605,605],
      [129,33,0,39,24,25,121,0,0,16,17.1,18.4,19.6,2,0,4,2064,2372],
      [856,349,194,74,84,155,856,0,0,3,3,3,3,2,0,12,2551,2551],
      [127,56,14,10,39,0,25,94,0,13.1,14,15.8,16.9,1,0,7,1668,2010],
      [381,119,107,9,28,65,137,191,0,4.8,5.5,4.8,5.5,2,0,19,1817,1817],
      [234,117,19,93,0,5,231,3,0,21.8,21.8,21.8,21.8,1,0,10,5103,5103],
      [215,58,62,46,51,0,82,135,0,13.2,13.1,15.9,15.7,1,0,8,2836,3417],
      [1406,541,70,290,335,90,1326,0,0,10.6,11.3,10.5,11.1,4,0,1,14938,14698],
      [85,21,67,3,0,15,22,59,25,12.3,9.9,12.3,9.9,2,0,13,1049,1049],
      [59,10,32,3,21,5,71,0,0,18,14.9,21.7,18,1,0,10,1061,1278],
      [358,139,0,89,70,40,338,0,0,38.9,41.2,46.8,49.6,1,0,9,13919,16770],
      [73,40,0,12,10,0,0,62,0,50.3,59.3,60.7,71.4,1,0,7,3675,4428],
      [597,189,96,78,239,7,609,0,0,4.3,4.2,4.3,4.2,1,0,6,2542,2542],
      [276,90,120,34,14,0,101,139,18,8.1,8.7,8.1,8.7,1,0,2,2244,2244],
      [728,181,165,15,84,167,330,27,255,11.1,13.1,13.3,15.8,1,0,4,8046,9694],
      [59,0,55,0,0,0,11,11,33,83.8,89.9,101,108.3,1,0,6,4945,5958],
      [98,36,32,9,17,0,45,42,7,13.4,14,16.1,16.8,1,0,11,1313,1582],
      [756,452,66,127,84,5,302,320,112,4.3,4.4,4.3,4.4,1,0,7,3214,3214],
      [155,120,34,0,0,0,47,107,0,3.1,3.1,3.8,3.8,1,0,10,483,582],
      [544,125,104,107,133,0,107,362,0,4.2,4.9,5.1,5.9,1,0,4,2306,2778],
      [813,27,677,34,0,100,18,820,0,2,1.9,2,1.9,2,0,9,1634,1634],
      [75,23,0,30,27,14,94,0,0,9.6,7.7,9.6,7.7,1,0,6,720,720],
      [112,85,4,16,14,0,119,0,0,9.6,9,9.6,9,4,0,13,1073,1073],
      [211,73,32,79,22,5,111,100,0,16.9,16.9,16.9,16.9,1,0,13,3566,3566],
      [895,222,271,222,63,0,778,0,0,0.9,1,0.9,1,1,0,7,780,780],
      [74,18,7,37,7,5,74,0,0,54,54,54,54,1,0,14,3995,3995],
      [3331,1049,519,399,595,360,2922,0,0,14.7,16.8,14.7,16.8,4,0,42,49034,49034],
      [64,15,18,9,15,5,12,39,11,6.1,6.3,7.4,7.6,1,0,6,392,472],
      [1402,328,804,187,49,63,1431,0,0,12.6,12.3,12.3,12,1,0,23,17607,17219],
      [337,128,21,86,77,25,337,0,0,1.8,1.8,1.9,1.9,1,0,8,591,657],
      [73,0,0,67,0,10,39,38,0,11.1,10.5,13.4,12.7,1,0,6,812,978],
      [64,12,28,17,7,0,47,17,0,8.8,8.8,10.6,10.6,1,0,12,564,680],
      [1703,186,463,0,516,316,1481,0,0,5,5.8,5,5.8,3,0,8,8549,8549],
      [151,41,21,29,41,19,151,0,0,2.6,2.6,2.9,2.9,1,0,3,391,434],
      [66,27,14,6,17,0,42,22,0,27.5,28.4,33.2,34.2,1,0,2,1817,2189],
      [70,24,0,3,42,5,74,0,0,7.7,7.3,9.4,8.9,2,0,3,540,659],
      [754,301,130,204,90,0,213,512,0,9.9,10.3,11.9,12.4,1,0,8,7443,8967],
      [325,106,49,31,80,12,136,142,0,26.7,31.2,32.1,37.5,1,0,6,8663,10437],
      [168,84,7,45,40,22,198,0,0,27.5,23.3,27.5,23.3,2,0,12,4622,4622],
      [226,99,50,43,63,5,260,0,0,4,3.5,4,3.5,4,0,7,915,915],
      [335,83,71,71,111,17,353,0,0,75.8,72,75.8,72,4,0,12,25401,25401],
      [76,21,51,3,0,0,63,12,0,7.5,7.6,9,9.1,1,0,5,569,686],
      [221,31,133,0,45,5,53,161,0,6.8,7.1,8.2,8.5,1,0,4,1512,1822],
      [1010,213,224,111,212,75,758,77,0,5,6.1,5,6.1,2,0,11,5053,5053],
      [116,46,12,22,35,15,130,0,0,16.7,14.9,16.7,14.9,1,0,10,1939,1939],
      [39,25,0,3,14,0,11,31,0,2.9,2.7,2.9,2.7,2,0,1,114,114],
      [170,75,12,23,39,0,108,41,0,9,10.3,9,10.3,4,0,8,1532,1532],
      [179,85,0,49,59,0,193,0,0,26.4,24.5,31.8,29.5,1,0,4,4723,5690],
      [166,126,0,38,0,0,0,164,0,17.9,18.1,21.6,21.8,1,0,13,2971,3580],
      [354,48,34,174,73,25,354,0,0,16.5,16.5,16.5,16.5,1,0,10,5841,5841],
      [615,546,0,74,7,0,627,0,0,1.5,1.5,1.5,1.5,2,0,8,941,941],
      [126,46,7,18,49,15,135,0,0,8.2,7.7,8.2,7.7,2,0,8,1035,1035],
      [1390,379,377,133,182,170,1241,0,0,4,4.5,4,4.5,3,0,13,5597,5597],
      [129,30,59,10,39,0,94,44,0,23.2,21.7,27.9,26.1,1,0,8,2988,3600],
      [203,35,48,6,14,100,203,0,0,15.9,15.9,15.9,15.9,1,0,5,3219,3219],
      [758,116,312,132,30,58,648,0,0,6.1,7.1,6.1,7.1,1,0,15,4630,4630],
      [558,92,116,57,196,0,461,0,0,7.4,8.9,7.4,8.9,1,0,6,4112,4112],
      [25,14,0,4,7,0,22,0,3,23.2,23.2,23.2,23.2,1,0,6,580,580],
      [850,94,348,205,45,74,320,446,0,12.9,14.3,15.5,17.2,1,0,5,10942,13183],
      [235,78,10,123,68,0,13,82,184,4,3.4,4.8,4,1,0,9,937,1129],
      [58,15,0,19,22,0,26,30,0,43.4,44.9,52.2,54.1,1,0,8,2515,3030],
      [316,14,118,14,155,0,139,151,11,8.2,8.6,8.2,8.6,2,0,8,2600,2600],
      [7633,1240,2455,135,1732,1572,1376,5193,565,3.3,3.5,3.3,3.5,2,0,19,25217,25217],
      [119,0,118,0,0,0,95,19,4,1.5,1.5,1.8,1.8,1,0,2,176,212],
      [55,12,17,6,14,10,59,0,0,6.2,5.8,7.5,7,1,0,3,341,411],
      [1644,240,858,177,91,115,1481,0,0,9.9,11,9.9,11,1,0,38,16357,16357],
      [1193,196,667,149,115,54,516,485,180,2.5,2.5,3,3.1,1,0,12,3006,3622],
      [605,155,231,91,105,0,582,0,0,2.8,2.9,3.4,3.5,1,0,8,1694,2041],
      [389,120,94,77,63,10,198,166,0,2.9,3.1,2.9,3.1,2,0,6,1134,1134],
      [132,56,0,27,38,7,128,0,0,9,9.3,10.8,11.2,1,0,8,1186,1429],
      [132,30,50,22,24,0,39,27,60,10.5,11,12.6,13.2,1,0,9,1383,1666],
      [286,94,36,44,38,55,267,0,0,6,6.5,6,6.5,1,0,6,1727,1727],
      [305,73,87,39,63,10,272,0,0,14.8,16.6,14.8,16.6,3,0,7,4504,4504],
      [268,73,105,0,70,0,248,0,0,17.9,19.4,20.6,22.2,2,0,8,4800,5517],
      [110,36,15,0,49,10,110,0,0,23.2,23.2,23.2,23.2,2,0,24,2553,2553],
      [3963,1184,616,952,1091,42,3885,0,0,4.3,4.4,4.3,4.4,2,0,11,16921,16921],
      [397,83,252,16,58,0,409,0,0,18.8,18.2,22.6,22,1,0,7,7459,8987],
      [254,90,39,3,117,0,119,100,30,15.3,15.6,15.3,15.6,2,0,11,3877,3877],
      [134,73,0,22,14,0,33,76,0,15.6,19.2,18.8,23.1,1,0,8,2088,2516],
      [266,101,70,26,56,5,258,0,0,17.7,18.2,21.3,21.9,1,0,8,4695,5657],
      [237,114,11,44,42,0,181,30,0,13.5,15.2,16.3,18.3,1,0,9,3201,3857],
      [1243,555,15,245,394,10,1219,0,0,9.2,9.4,11.1,11.4,1,0,9,11490,13843],
      [666,138,233,124,105,5,605,0,0,1.1,1.2,1.1,1.2,1,0,13,752,752],
      [1810,349,423,377,457,10,1616,0,0,16.2,18.2,16.2,18.2,3,0,35,29399,29399],
      [88,56,7,15,7,0,9,76,0,26.1,27,31.5,32.6,1,0,6,2299,2770],
      [62,19,8,9,15,0,51,0,0,14.2,17.3,15.3,18.6,1,0,5,883,949],
      [305,59,102,19,60,21,138,123,0,28.5,33.3,34.4,40.2,1,0,10,8702,10484],
      [349,107,93,97,52,0,286,63,0,10.6,10.6,10.6,10.6,1,0,8,3703,3703],
      [156,0,133,0,10,0,143,0,0,4.5,4.9,5.4,5.9,1,0,4,705,849],
      [100,24,76,3,7,0,40,70,0,14.3,13,14.3,13,1,0,15,1434,1434],
      [222,20,5,93,73,0,47,144,0,11,12.8,13.3,15.5,1,0,4,2450,2952],
      [506,54,161,43,173,80,511,0,0,6.9,6.8,6.9,6.8,1,0,9,3500,3500],
      [123,28,0,47,15,25,115,0,0,15.4,16.5,17.7,18.9,2,0,3,1896,2179],
      [252,0,109,143,0,0,109,143,0,27.1,27.1,27.1,27.1,2,0,11,6821,6821],
      [258,186,40,19,10,0,0,255,0,5.4,5.5,6.5,6.6,1,0,4,1393,1678],
      [166,67,88,6,0,0,37,120,4,15.7,16.2,18.9,19.5,1,0,7,2604,3137],
      [181,45,39,38,42,5,169,0,0,20.1,21.5,22.6,24.2,2,0,10,3638,4088],
      [284,99,112,26,28,0,220,27,18,11.4,12.2,11.4,12.2,1,0,4,3234,3234],
      [52,0,60,0,0,0,0,55,5,4.8,4.2,5.8,5.1,1,0,3,252,304],
      [102,72,0,18,0,7,0,97,0,10.1,10.6,12.1,12.8,1,0,3,1028,1239],
      [58,26,29,3,0,0,22,36,0,11.9,11.9,14.4,14.4,1,0,5,691,833],
      [1196,626,108,56,413,5,1208,0,0,6.5,6.5,6.5,6.5,4,0,15,7824,7824],
      [38,30,0,8,0,0,32,0,6,6.5,6.5,6.5,6.5,1,0,4,247,247],
      [84,33,0,21,27,0,61,20,0,32.6,33.8,39.3,40.7,1,0,10,2738,3299],
      [73,18,14,8,44,0,40,44,0,15.4,13.3,18.5,16.1,1,0,6,1121,1351],
      [449,352,12,12,52,0,0,428,0,35.7,37.5,43,45.2,1,0,8,16042,19328],
      [551,188,116,52,114,5,223,231,21,4.4,5.1,5.3,6.2,1,0,13,2435,2934],
      [194,48,47,28,27,35,185,0,0,7.4,7.8,7.4,7.8,2,0,8,1440,1440],
      [185,36,14,50,32,10,142,0,0,34.7,45.2,34.7,45.2,1,0,16,6416,6416],
      [134,43,0,77,36,0,156,0,0,9.1,7.8,10.9,9.4,1,0,5,1213,1461],
      [1241,575,45,319,301,0,1240,0,0,8.2,8.2,8.2,8.2,1,0,15,10222,10222],
      [99,81,0,3,15,0,6,93,0,2.4,2.4,2.4,2.4,1,0,3,241,241],
      [1285,685,67,133,620,7,1512,0,0,0.9,0.8,0.9,0.8,1,0,16.5,1200,1200],
      [466,164,212,12,66,7,461,0,0,3.7,3.7,4.4,4.5,1,0,10,1708,2058],
      [77,30,0,20,22,0,7,65,0,27.4,29.3,33,35.3,1,0,4,2108,2540],
      [81,11,22,0,20,21,64,10,0,5.6,6.1,6.8,7.4,1,0,1,454,547],
      [694,61,164,168,145,60,598,0,0,5.9,6.8,5.9,6.8,4,0,8,4086,4086],
      [62,18,7,6,10,17,7,51,0,32.7,34.9,39.4,42.1,1,0,5,2027,2442],
      [56,0,42,0,0,15,57,0,0,5.2,5.1,5.2,5.1,1,0,3,293,293],
      [753,289,13,0,363,7,672,0,0,5.7,6.4,5.7,6.4,1,0,12,4301,4301],
      [421,177,22,217,0,5,421,0,0,39.9,39.9,39.9,39.9,1,0,15.5,16788,16788],
      [59,30,11,3,21,0,65,0,0,9.6,8.7,11.6,10.5,1,0,3,566,682],
      [409,42,201,39,67,60,409,0,0,6.5,6.5,6.5,6.5,2,0,11,2672,2672],
      [115,21,90,4,0,0,94,21,0,16.3,16.3,16.3,16.3,2,0,12,1869,1869],
      [93,58,20,4,10,0,22,70,0,8.6,8.7,10.4,10.5,1,0,3,803,967],
      [71,30,15,12,7,5,0,69,0,56.6,58.2,68.2,70.2,1,0,7,4019,4842],
      [971,345,42,249,150,10,796,0,0,5,6.1,6,7.4,1,0,14,4867,5864],
      [74,15,7,42,0,10,74,0,0,42.3,42.3,42.3,42.3,1,0,17,3132,3132],
      [81,18,4,25,21,10,25,30,23,1.1,1.1,1.3,1.4,1,0,1,89,107],
      [106,6,33,19,0,55,113,0,0,10.6,10,12.8,12,1,0,7,1126,1357],
      [1168,516,240,176,314,10,1256,0,0,1.3,1.2,1.3,1.2,3,0,8,1538,1538],
      [1093,392,119,235,166,47,959,0,0,6.6,7.6,6.6,7.6,1,0,11,7263,7263],
      [67,10,18,31,0,0,0,59,0,57.5,65.3,69.3,78.7,1,0,2,3853,4642],
      [1256,270,121,450,90,50,981,0,0,23,29.4,41,52.5,1,0,28,28855,51527],
      [72,67,5,0,0,0,6,66,0,17.3,17.3,20.9,20.9,1,0,15,1248,1504],
      [777,287,159,38,147,45,676,0,0,19.4,22.2,22.2,25.6,2,0,13,15039,17286],
      [131,30,33,18,35,12,128,0,0,37.8,38.6,45.5,46.6,1,0,13,4947,5960],
      [134,78,0,0,63,0,141,0,0,15.1,14.3,18.2,17.3,1,0,8,2019,2433],
      [826,255,295,72,157,0,779,0,0,6.5,6.9,6.5,6.9,1,0,42,5400,5400],
      [3180,916,538,295,969,0,2718,0,0,10.4,12.2,10.4,12.2,4,0,36,33028,33028],
      [324,175,108,29,17,5,334,0,0,15.7,15.2,15.7,15.2,1,0,13,5078,5078],
      [220,132,45,30,7,0,49,165,0,3.2,3.3,3.2,3.3,1,0,3,701,701],
      [258,34,89,6,63,49,241,0,0,2.9,3.1,2.9,3.1,1,0,12,736,736],
      [139,25,19,6,29,60,139,0,0,7,7,7,7,2,0,7,976,976],
      [274,70,123,57,28,30,308,0,0,4.3,3.8,4.3,3.8,2,0,4,1167,1167],
      [231,0,86,0,50,130,266,0,0,16.3,14.1,16.3,14.1,4,0,12,3762,3762],
      [126,58,15,6,21,40,22,118,0,4.9,4.4,4.9,4.4,2,0,5,619,619],
      [93,0,70,0,15,10,0,95,0,11.8,11.6,14.3,14,1,0,8,1101,1327],
      [1825,594,569,192,259,60,1674,0,0,0.7,0.7,0.7,0.7,1,0,15,1210,1210],
      [500,229,31,130,60,0,170,227,53,11.8,13.1,14.2,15.7,1,0,8,5876,7080],
      [373,129,96,21,105,50,389,12,0,6.4,6,6.4,6,2,0,10,2395,2395],
      [330,179,26,64,110,0,379,0,0,3.2,2.8,3.2,2.8,1,0,10,1050,1050],
      [57,27,28,0,0,0,0,55,0,30.5,31.7,36.8,38.1,1,0,4,1741,2098],
      [127,61,0,20,44,0,13,98,14,12.4,12.6,15,15.2,1,0,4,1579,1902],
      [1362,579,291,171,378,0,1419,0,0,2.3,2.3,2.3,2.3,3,0,11,3193,3193],
      [1463,780,119,223,371,0,1493,0,0,24.6,24.1,24.6,24.1,4,0,23,36046,36046],
      [148,12,49,36,28,15,140,0,0,23.2,24.6,28,29.6,1,0,3,3437,4141],
      [474,71,24,343,21,15,41,433,0,3.9,3.9,3.9,3.9,1,0,6,1829,1829],
      [77,24,18,21,14,0,18,59,0,5.3,5.3,6.4,6.4,1,0,10,408,492],
      [213,105,67,41,0,0,52,161,0,3.8,3.8,3.8,3.8,1,0,2.5,801,801],
      [175,22,53,0,100,0,59,116,0,3.4,3.4,3.4,3.4,2,0,7,597,597],
      [360,122,98,54,62,0,336,0,0,2.1,2.3,2.1,2.3,1,0,18,763,763],
      [331,84,0,12,0,284,156,96,128,3.7,3.3,3.7,3.3,2,0,5,1238,1238],
      [285,48,187,15,35,25,310,0,0,4.4,4,4.4,4,2,0,7,1249,1249],
      [187,72,32,10,44,5,4,159,0,73.5,84.4,84.5,97,2,0,3,13752,15807],
      [502,120,32,89,83,120,444,0,0,18.5,20.9,18.5,20.9,1,0,14,9296,9296],
      [303,0,266,0,0,25,0,291,0,1.1,1.1,1.3,1.4,1,0,1,329,396],
      [174,105,83,0,0,5,98,35,60,17.7,16,17.7,16,2,0,17,3088,3088],
      [44,14,0,16,17,5,49,3,0,8.6,7.3,8.6,7.3,4,0,2,380,380],
      [387,88,221,37,34,0,18,362,0,6,6.1,7.3,7.4,1,0,7,2333,2811],
      [406,18,374,27,0,0,21,398,0,5.2,5,5.2,5,2,0,19,2109,2109],
      [496,198,109,67,90,60,524,0,0,20.3,19.2,23.4,22.1,2,0,14,10080,11586],
      [116,34,38,4,30,0,33,73,0,4.8,5.2,4.8,5.2,1,0,2,553,553],
      [53,17,17,0,24,5,63,0,0,6.7,5.6,6.7,5.6,2,0,16,354,354],
      [209,42,145,10,43,0,225,15,0,0.9,0.8,0.9,0.8,1,0,2.5,190,190],
      [903,336,134,158,148,100,387,303,186,6.1,6.3,7.3,7.5,1,0,11,5482,6605],
      [469,71,170,15,67,96,419,0,0,6.8,7.6,8.2,9.2,1,0,11,3191,3845],
      [1894,187,1241,143,156,10,966,696,75,2.1,2.3,2.1,2.3,2,0,12,3986,3986],
      [215,108,0,94,7,0,76,133,0,2.6,2.7,2.6,2.7,1,0,7,560,560],
      [82,38,9,20,14,0,29,52,0,1,1,1.2,1.2,1,0,2,80,96],
      [1694,391,469,385,210,85,1540,0,0,4.6,5.1,4.6,5.1,1,0,16,7816,7816],
      [81,24,22,20,10,0,64,4,8,24.7,26.3,29.8,31.7,1,0,5,2002,2412],
      [297,150,7,132,0,0,13,264,12,5.2,5.4,5.2,5.4,1,0,6,1557,1557],
      [280,161,91,0,10,0,262,0,0,5.1,5.4,5.1,5.4,4,0,7,1417,1417],
      [56,19,5,16,10,0,29,21,0,22.3,24.9,26.8,30,1,0,5,1246,1501],
      [492,114,97,157,49,75,248,244,0,8.5,8.5,8.5,8.5,1,0,11,4158,4158],
      [426,127,122,54,87,20,31,352,27,1.5,1.6,1.8,1.9,1,0,2,646,778],
      [499,262,42,60,90,0,155,299,0,4.6,5.1,4.6,5.1,1,0,10,2310,2310],
      [60,9,32,12,7,0,60,0,0,16.5,16.5,18.4,18.4,1,0,5,992,1102],
      [362,152,68,41,72,15,348,0,0,19.6,20.4,23.6,24.5,1,0,6,7091,8543],
      [363,169,23,115,42,0,82,267,0,9.5,9.8,11.4,11.8,1,0,5,3431,4134],
      [53,24,0,24,0,0,0,48,0,19,21,22.9,25.3,1,0,3,1007,1213],
      [17518,9404,1221,0,2955,0,13580,0,0,3.1,4,3.1,4,1,0,14,54620,54620],
      [199,82,92,13,10,0,20,100,77,4.4,4.4,5.3,5.3,1,0,2,871,1049],
      [2171,534,319,323,87,0,209,984,70,9.1,15.6,9.1,15.6,1,0,8,19699,19699],
      [220,90,19,64,39,0,12,200,0,8.8,9.1,10.6,11,1,0,4,1930,2325],
      [1355,535,428,58,224,10,1255,0,0,5.5,6,5.5,6,1,0,26,7505,7505],
      [374,170,4,88,126,10,398,0,0,0.8,0.8,1,0.9,1,0,2,300,363],
      [62,51,0,0,10,5,66,0,0,5.6,5.3,6.8,6.4,1,0,3,349,420],
      [311,11,217,3,36,57,324,0,0,6.6,6.3,7.9,7.6,1,0,6,2038,2455],
      [132,32,15,13,31,45,136,0,0,4.6,4.4,5.5,5.3,1,0,6,601,724],
      [135,60,17,0,70,0,0,147,0,4.9,4.5,4.9,4.5,2,0,15,667,667],
      [79,16,34,0,28,10,81,7,0,45.4,40.7,54.7,49.1,1,0,5,3585,4319],
      [155,75,28,10,29,0,14,128,0,12.4,13.5,14.9,16.3,1,0,4,1916,2308],
      [965,433,234,148,245,0,1060,0,0,3.8,3.4,4.1,3.7,1,0,30,3655,3930],
      [296,27,166,48,21,50,312,0,0,18.4,17.4,18.4,17.4,2,0,10,5432,5432],
      [56,3,19,10,24,0,56,0,0,3,3,3,3,2,0,3,170,170],
      [206,88,23,31,35,0,73,104,0,8.8,10.3,10.7,12.4,1,0,8,1823,2196],
      [651,104,385,16,49,27,581,0,0,5.5,6.2,6.7,7.5,1,0,4,3612,4352],
      [2323,804,332,0,947,240,636,1552,135,1.7,1.7,1.7,1.7,2,0,6,3981,3981],
      [146,46,0,50,41,0,44,93,0,13.6,14.5,16.4,17.4,1,0,6,1984,2390],
      [284,49,83,75,51,5,80,183,0,12.8,13.9,15.5,16.7,1,0,5,3646,4393],
      [249,47,26,80,84,0,237,0,0,15.3,16,15.3,16,2,0,9,3800,3800],
      [32,4,7,0,0,30,41,0,0,15.6,12.1,15.6,12.1,1,0,3,498,498],
      [1908,401,1216,155,107,10,1889,0,0,14.2,14.3,14.2,14.3,3,0,48,27000,27000],
      [253,56,149,0,24,24,76,177,0,6.7,6.7,6.7,6.7,1,0,7,1694,1694],
      [184,53,21,43,38,15,170,0,0,16,17.4,18.4,20,2,0,4,2952,3393],
      [76,60,12,0,0,0,0,72,0,4.9,5.2,5.9,6.3,1,0,1,374,451],
      [276,108,5,75,56,0,177,53,14,1.1,1.2,1.1,1.2,1,0,4,300,300],
      [3471,1327,257,534,995,42,3155,0,0,2.2,2.4,2.2,2.4,4,0,17,7575,7575],
      [380,67,103,77,98,20,365,0,0,8.7,9.1,10.5,11,1,0,9,3322,4002],
      [155,18,0,69,14,47,148,0,0,33.5,35.1,33.5,35.1,1,0,8,5196,5196],
      [327,64,142,21,0,100,327,0,0,7.8,7.8,7.8,7.8,2,0,16,2566,2566],
      [193,82,80,50,14,0,41,182,3,8.7,7.5,10.5,9,1,0,5,1686,2031],
      [1108,279,20,314,273,30,916,0,0,22.6,27.4,24.3,29.4,1,0,6,25054,26940],
      [363,168,10,92,77,5,0,352,0,0.3,0.3,0.4,0.4,1,0,10,117,141],
      [249,144,104,6,14,0,268,0,0,2,1.9,2,1.9,1,0,3,500,500],
      [769,265,195,235,52,0,178,557,12,16.3,16.8,16.3,16.8,1,0,8,12551,12551],
      [137,54,42,30,7,0,97,36,0,2.9,3,2.9,3,1,0,3,399,399],
      [579,215,81,109,112,0,517,0,0,1.4,1.5,1.4,1.5,1,0,7,784,784],
      [133,39,0,41,24,20,124,0,0,15.9,17,18.3,19.6,2,0,6,2112,2428],
      [78,7,34,6,21,0,22,46,0,7.7,8.8,8.8,10.1,2,0,3,600,690],
      [101,12,31,3,50,0,65,28,3,4.5,4.7,4.5,4.7,1,0,1.5,450,450],
      [1222,503,333,173,150,5,1164,0,0,4.7,5,4.7,5,1,0,20,5800,5800],
      [1093,486,277,126,147,5,788,253,0,2.3,2.5,2.3,2.5,2,0,7,2565,2565],
      [222,41,57,0,99,25,222,0,0,10.7,10.6,10.7,10.6,2,0,4,2385,2385],
      [2067,1056,658,45,303,5,1510,557,0,5,5,5,5,2,0,21,10398,10398],
      [175,65,31,22,38,0,141,15,0,19.6,22,23.6,26.5,1,0,10,3434,4137],
      [230,180,12,41,14,0,247,0,0,1.7,1.6,6,5.6,1,0,3,400,1379],
      [104,32,5,40,28,10,115,0,0,3.3,2.9,4.9,4.5,4,0,2,338,512],
      [177,24,79,6,42,60,211,0,0,16,13.4,16,13.4,2,0,17,2835,2835],
      [62,33,0,12,10,0,22,33,0,9.6,10.8,11.5,13,1,0,2,594,716],
      [487,146,238,53,24,12,45,428,0,2.1,2.2,2.1,2.2,1,0,6,1017,1017],
      [177,40,12,27,38,60,177,0,0,4.5,4.5,5.4,5.4,1,0,8,789,951],
      [105,34,66,10,37,15,162,0,0,7.4,4.8,7.4,4.8,1,0,3,774,774],
      [140,43,68,3,57,0,171,0,0,4.6,3.7,4.6,3.7,4,0,1.5,640,640],
      [230,81,49,37,58,0,225,0,0,2.2,2.2,2.2,2.2,1,0,4,500,500],
      [236,102,84,52,0,0,238,0,0,2.5,2.5,2.8,2.8,1,0,10,601,668],
      [846,322,56,112,234,5,729,0,0,19.1,22.2,19.1,22.2,1,0,13,16179,16179],
      [139,18,21,30,70,0,139,0,0,17.6,17.6,17.6,17.6,2,0,6,2446,2446],
      [51,12,27,0,0,7,7,39,0,6.6,7.3,6.6,7.3,1,0,3,338,338],
      [195,57,32,12,140,0,241,0,0,9.2,7.4,11,8.9,1,0,9,1786,2152],
      [51,32,0,16,7,0,0,55,0,17.6,16.3,21.2,19.7,1,0,3,899,1083],
      [1106,410,267,108,152,25,962,0,0,15,17.2,17.2,19.8,2,0,20,16560,19034],
      [99,13,32,3,42,5,95,0,0,5.3,5.5,6.4,6.7,1,0,4,526,634],
      [56,24,0,9,14,0,47,0,0,7.9,9.4,7.9,9.4,2,0,6,440,440],
      [213,123,91,28,0,0,36,206,0,10.3,9,10.3,9,1,0,7,2185,2185]
    ]
    )

def nasa93(opt=options(),tunings=tunings()):
  vl=1;l=2;n=3;h=4;vh=5;xh=6
  return Thing(
    sfem=21,
    kloc=22,
    effort=23,
    names= [ 
     # 0..8
     'Prec', 'Flex', 'Resl', 'Team', 'Pmat', 'rely', 'data', 'cplx', 'ruse',
     # 9 .. 17
     'docu', 'time', 'stor', 'pvol', 'acap', 'pcap', 'pcon', 'aexp', 'plex',  
     # 18 .. 25
     'ltex', 'tool', 'site', 'sced', 'kloc', 'effort', '?defects', '?months'],
    projects=[
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,25.9,117.6,808,15.3],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,24.6,117.6,767,15.0],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,7.7,31.2,240,10.1],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,8.2,36,256,10.4],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,9.7,25.2,302,11.0],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,2.2,8.4,69,6.6],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,3.5,10.8,109,7.8],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,66.6,352.8,2077,21.0],
	[h,h,h,vh,h,h,l,h,n,n,xh,xh,l,h,h,n,h,n,h,h,n,n,7.5,72,226,13.6],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,h,vh,n,vh,n,h,n,n,n,20,72,566,14.4],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,h,h,n,vh,n,h,n,n,n,6,24,188,9.9],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,h,vh,n,vh,n,h,n,n,n,100,360,2832,25.2],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,h,n,n,vh,n,l,n,n,n,11.3,36,456,12.8],
	[h,h,h,vh,n,n,l,h,n,n,n,n,h,h,h,n,h,l,vl,n,n,n,100,215,5434,30.1],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,h,h,n,vh,n,h,n,n,n,20,48,626,15.1],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,h,n,n,n,n,vl,n,n,n,100,360,4342,28.0],
	[h,h,h,vh,n,n,l,h,n,n,n,xh,l,h,vh,n,vh,n,h,n,n,n,150,324,4868,32.5],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,h,h,n,h,n,h,n,n,n,31.5,60,986,17.6],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,h,h,n,vh,n,h,n,n,n,15,48,470,13.6],
	[h,h,h,vh,n,n,l,h,n,n,n,xh,l,h,n,n,h,n,h,n,n,n,32.5,60,1276,20.8],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,19.7,60,614,13.9],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,66.6,300,2077,21.0],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,29.5,120,920,16.0],
	[h,h,h,vh,n,h,n,n,n,n,h,n,n,n,h,n,h,n,n,n,n,n,15,90,575,15.2],
	[h,h,h,vh,n,h,n,h,n,n,n,n,n,n,h,n,h,n,n,n,n,n,38,210,1553,21.3],
	[h,h,h,vh,n,n,n,n,n,n,n,n,n,n,h,n,h,n,n,n,n,n,10,48,427,12.4],
	[h,h,h,vh,h,n,vh,h,n,n,vh,vh,l,vh,n,n,h,l,h,n,n,l,15.4,70,765,14.5],
	[h,h,h,vh,h,n,vh,h,n,n,vh,vh,l,vh,n,n,h,l,h,n,n,l,48.5,239,2409,21.4],
	[h,h,h,vh,h,n,vh,h,n,n,vh,vh,l,vh,n,n,h,l,h,n,n,l,16.3,82,810,14.8],
	[h,h,h,vh,h,n,vh,h,n,n,vh,vh,l,vh,n,n,h,l,h,n,n,l,12.8,62,636,13.6],
	[h,h,h,vh,h,n,vh,h,n,n,vh,vh,l,vh,n,n,h,l,h,n,n,l,32.6,170,1619,18.7],
	[h,h,h,vh,h,n,vh,h,n,n,vh,vh,l,vh,n,n,h,l,h,n,n,l,35.5,192,1763,19.3],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,5.5,18,172,9.1],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,10.4,50,324,11.2],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,14,60,437,12.4],
	[h,h,h,vh,n,h,n,h,n,n,n,n,n,n,n,n,n,n,n,n,n,n,6.5,42,290,12.0],
	[h,h,h,vh,n,n,n,h,n,n,n,n,n,n,n,n,n,n,n,n,n,n,13,60,683,14.8],
	[h,h,h,vh,h,n,n,h,n,n,n,n,n,n,h,n,n,n,h,h,n,n,90,444,3343,26.7],
	[h,h,h,vh,n,n,n,h,n,n,n,n,n,n,n,n,n,n,n,n,n,n,8,42,420,12.5],
	[h,h,h,vh,n,n,n,h,n,n,h,n,n,n,n,n,n,n,n,n,n,n,16,114,887,16.4],
	[h,h,h,vh,h,n,h,h,n,n,vh,h,l,h,h,n,n,l,h,n,n,l,177.9,1248,7998,31.5],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,h,n,n,n,n,n,n,n,302,2400,8543,38.4],
	[h,h,h,vh,h,n,h,l,n,n,n,n,h,h,n,n,h,n,n,h,n,n,282.1,1368,9820,37.3],
	[h,h,h,vh,h,h,h,l,n,n,n,n,n,h,n,n,h,n,n,n,n,n,284.7,973,8518,38.1],
	[h,h,h,vh,n,h,h,n,n,n,n,n,l,n,h,n,h,n,h,n,n,n,79,400,2327,26.9],
	[h,h,h,vh,l,l,n,n,n,n,n,n,l,h,vh,n,h,n,h,n,n,n,423,2400,18447,41.9],
	[h,h,h,vh,h,n,n,n,n,n,n,n,l,h,vh,n,vh,l,h,n,n,n,190,420,5092,30.3],
	[h,h,h,vh,h,n,n,h,n,n,n,h,n,h,n,n,h,n,h,n,n,n,47.5,252,2007,22.3],
	[h,h,h,vh,l,vh,n,xh,n,n,h,h,l,n,n,n,h,n,n,h,n,n,21,107,1058,21.3],
	[h,h,h,vh,l,n,h,h,n,n,vh,n,n,h,h,n,h,n,h,n,n,n,78,571.4,4815,30.5],
	[h,h,h,vh,l,n,h,h,n,n,vh,n,n,h,h,n,h,n,h,n,n,n,11.4,98.8,704,15.5],
	[h,h,h,vh,l,n,h,h,n,n,vh,n,n,h,h,n,h,n,h,n,n,n,19.3,155,1191,18.6],
	[h,h,h,vh,l,h,n,vh,n,n,h,h,l,h,n,n,n,h,h,n,n,n,101,750,4840,32.4],
	[h,h,h,vh,l,h,n,h,n,n,h,h,l,n,n,n,h,n,n,n,n,n,219,2120,11761,42.8],
	[h,h,h,vh,l,h,n,h,n,n,h,h,l,n,n,n,h,n,n,n,n,n,50,370,2685,25.4],
	[h,h,h,vh,h,vh,h,h,n,n,vh,vh,n,vh,vh,n,vh,n,h,h,n,l,227,1181,6293,33.8],
	[h,h,h,vh,h,n,h,vh,n,n,n,n,l,h,vh,n,n,l,n,n,n,l,70,278,2950,20.2],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,0.9,8.4,28,4.9],
	[h,h,h,vh,l,vh,l,xh,n,n,xh,vh,l,h,h,n,vh,vl,h,n,n,n,980,4560,50961,96.4],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,vh,vh,n,n,h,h,n,n,n,350,720,8547,35.7],
	[h,h,h,vh,h,h,n,xh,n,n,h,h,l,h,n,n,n,h,h,h,n,n,70,458,2404,27.5],
	[h,h,h,vh,h,h,n,xh,n,n,h,h,l,h,n,n,n,h,h,h,n,n,271,2460,9308,43.4],
	[h,h,h,vh,n,n,n,n,n,n,n,n,l,h,h,n,h,n,h,n,n,n,90,162,2743,25.0],
	[h,h,h,vh,n,n,n,n,n,n,n,n,l,h,h,n,h,n,h,n,n,n,40,150,1219,18.9],
	[h,h,h,vh,n,h,n,h,n,n,h,n,l,h,h,n,h,n,h,n,n,n,137,636,4210,32.2],
	[h,h,h,vh,n,h,n,h,n,n,h,n,h,h,h,n,h,n,h,n,n,n,150,882,5848,36.2],
	[h,h,h,vh,n,vh,n,h,n,n,h,n,l,h,h,n,h,n,h,n,n,n,339,444,8477,45.9],
	[h,h,h,vh,n,l,h,l,n,n,n,n,h,h,h,n,h,n,h,n,n,n,240,192,10313,37.1],
	[h,h,h,vh,l,h,n,h,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,144,576,6129,28.8],
	[h,h,h,vh,l,n,l,n,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,151,432,6136,26.2],
	[h,h,h,vh,l,n,l,h,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,34,72,1555,16.2],
	[h,h,h,vh,l,n,n,h,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,98,300,4907,24.4],
	[h,h,h,vh,l,n,n,h,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,85,300,4256,23.2],
	[h,h,h,vh,l,n,l,n,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,20,240,813,12.8],
	[h,h,h,vh,l,n,l,n,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,111,600,4511,23.5],
	[h,h,h,vh,l,h,vh,h,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,162,756,7553,32.4],
	[h,h,h,vh,l,h,h,vh,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,352,1200,17597,42.9],
	[h,h,h,vh,l,h,n,vh,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,165,97,7867,31.5],
	[h,h,h,vh,h,h,n,vh,n,n,h,h,l,h,n,n,n,h,h,n,n,n,60,409,2004,24.9],
	[h,h,h,vh,h,h,n,vh,n,n,h,h,l,h,n,n,n,h,h,n,n,n,100,703,3340,29.6],
	[h,h,h,vh,n,h,vh,vh,n,n,xh,xh,h,n,n,n,n,l,l,n,n,n,32,1350,2984,33.6],
	[h,h,h,vh,h,h,h,h,n,n,vh,xh,h,h,h,n,h,h,h,n,n,n,53,480,2227,28.8],
	[h,h,h,vh,h,h,l,vh,n,n,vh,xh,l,vh,vh,n,vh,vl,vl,h,n,n,41,599,1594,23.0],
	[h,h,h,vh,h,h,l,vh,n,n,vh,xh,l,vh,vh,n,vh,vl,vl,h,n,n,24,430,933,19.2],
	[h,h,h,vh,h,vh,h,vh,n,n,xh,xh,n,h,h,n,h,h,h,n,n,n,165,4178.2,6266,47.3],
	[h,h,h,vh,h,vh,h,vh,n,n,xh,xh,n,h,h,n,h,h,h,n,n,n,65,1772.5,2468,34.5],
	[h,h,h,vh,h,vh,h,vh,n,n,xh,xh,n,h,h,n,h,h,h,n,n,n,70,1645.9,2658,35.4],
	[h,h,h,vh,h,vh,h,xh,n,n,xh,xh,n,h,h,n,h,h,h,n,n,n,50,1924.5,2102,34.2],
	[h,h,h,vh,l,vh,l,vh,n,n,vh,xh,l,h,n,n,l,vl,l,h,n,n,7.25,648,406,15.6],
	[h,h,h,vh,h,vh,h,vh,n,n,xh,xh,n,h,h,n,h,h,h,n,n,n,233,8211,8848,53.1],
	[h,h,h,vh,n,h,n,vh,n,n,vh,vh,h,n,n,n,n,l,l,n,n,n,16.3,480,1253,21.5],
	[h,h,h,vh,n,h,n,vh,n,n,vh,vh,h,n,n,n,n,l,l,n,n,n,  6.2, 12,477,15.4],
	[h,h,h,vh,n,h,n,vh,n,n,vh,vh,h,n,n,n,n,l,l,n,n,n,  3.0, 38,231,12.0],
	])


def coc81(opt=options(),tunings=tunings()):
  vl=1;l=2;n=3;h=4;vh=5;xh=6
  return Thing(
    sfem=21,
    kloc=22,
    effort=23,
    names= [
     'Prec', 'Flex', 'Resl', 'Team', 'Pmat', 'rely', 'data', 'cplx', 'ruse',
     'docu', 'time', 'stor', 'pvol', 'acap', 'pcap', 'pcon', 'aexp', 'plex',  
     'ltex', 'tool', 'site', 'sced', 'kloc', 'effort', '?defects', '?months'],
    projects=[
      [h,h,h,vh,vl,l,vh,vl,n,n,n,h,h,l,l,n,l,l,n,vl,h,n,113,2040,13027,38.4],
      [h,h,h,vh,vl,l,vh,l,n,n,n,h,n,n,n,n,h,h,h,vl,h,n,293,1600,25229,48.6],
      [h,h,h,vh,n,n,vh,l,n,n,n,n,l,h,h,n,vh,h,h,l,h,n,132,243,3694,28.7],
      [h,h,h,vh,vl,vl,vh,vl,n,n,n,n,l,l,vl,n,h,n,h,vl,h,n,60,240,5688,28.0],
      [h,h,h,vh,vl,l,l,n,n,n,n,n,l,n,h,n,n,h,h,vl,h,n,16,33,970,14.3],
      [h,h,h,vh,vl,vl,n,l,n,n,n,vh,n,vl,vl,n,n,h,h,vl,h,n,4,43,553,11.6],
      [h,h,h,vh,n,vl,n,n,n,n,n,n,l,n,n,n,n,h,h,l,h,n,6.9,8,350,10.3],
      [h,h,h,vh,vl,h,l,vh,n,n,xh,xh,vh,vh,n,n,h,vl,vl,vl,h,l,22,1075,3511,24.5],
      [h,h,h,vh,n,h,l,vh,n,n,vh,vh,h,h,h,n,n,l,l,vl,h,n,30,423,1989,24.1],
      [h,h,h,vh,l,vh,l,vh,n,n,h,xh,n,h,h,n,vh,h,n,vl,h,n,29,321,1496,23.2],
      [h,h,h,vh,l,vh,l,vh,n,n,h,xh,n,h,h,n,vh,h,n,vl,h,n,32,218,1651,24.0],
      [h,h,h,vh,n,h,l,vh,n,n,h,h,n,h,h,n,vh,n,h,vl,h,l,37,201,1783,19.1],
      [h,h,h,vh,n,h,l,vh,n,n,h,h,h,vh,vh,n,n,l,n,vl,h,n,25,79,1138,18.4],
      [h,h,h,vh,vl,h,l,xh,n,n,vh,xh,h,h,vh,n,n,l,l,vl,h,vl,3,60,387,9.4],
      [h,h,h,vh,n,vh,l,vh,n,n,vh,h,h,h,h,n,l,vl,vl,vl,h,vl,3.9,61,276,9.5],
      [h,h,h,vh,l,vh,n,vh,n,n,vh,xh,n,h,h,n,n,n,n,vl,h,n,6.1,40,390,14.9],
      [h,h,h,vh,l,vh,n,vh,n,n,vh,xh,n,h,h,n,vh,n,n,vl,h,n,3.6,9,230,12.3],
      [h,h,h,vh,vl,h,vh,h,n,n,vh,vh,n,h,n,n,n,n,n,vl,h,l,320,11400,34588,52.4],
      [h,h,h,vh,n,h,h,n,n,n,h,vh,l,vh,n,n,h,n,n,l,h,n,1150,6600,41248,67.0],
      [h,h,h,vh,vl,vh,h,vh,n,n,h,vh,h,vh,n,n,vh,l,l,vl,h,l,299,6400,30955,53.4],
      [h,h,h,vh,n,n,vh,h,n,n,n,n,l,h,n,n,n,n,n,l,h,n,252,2455,11664,40.8],
      [h,h,h,vh,n,h,n,n,n,n,n,h,n,h,h,n,vh,h,n,vl,h,vl,118,724,5172,21.7],
      [h,h,h,vh,l,h,n,n,n,n,n,h,n,h,h,n,vh,h,n,vl,h,vl,77,539,4362,19.5],
      [h,h,h,vh,n,l,n,l,n,n,n,h,n,n,n,n,vl,l,h,n,h,n,90,453,4407,27.1],
      [h,h,h,vh,n,h,vh,vh,n,n,n,h,n,h,h,n,n,l,n,l,h,l,38,523,2269,20.2],
      [h,h,h,vh,n,n,n,l,n,n,n,h,h,h,h,n,n,l,n,vl,h,l,48,387,2419,18.5],
      [h,h,h,vh,n,h,l,h,n,n,n,vh,n,n,n,n,n,n,n,vl,h,l,9.4,88,517,12.1],
      [h,h,h,vh,vl,h,h,vh,n,n,h,vh,h,h,h,n,n,l,l,vl,h,n,13,98,1473,19.6],
      [h,h,h,vh,n,l,n,n,n,n,n,n,n,n,h,n,vl,n,n,l,h,vl,2.14,7.3,138,5.3],
      [h,h,h,vh,n,l,n,n,n,n,n,n,n,n,h,n,vl,n,n,l,h,vl,1.98,5.9,128,5.2],
      [h,h,h,vh,l,vh,h,n,n,n,n,xh,h,h,h,n,vh,l,l,vl,h,n,62,1063,3682,32.8],
      [h,h,h,vh,vl,l,h,l,n,n,n,n,n,vh,n,n,vh,n,n,vl,h,n,390,702,30484,45.8],
      [h,h,h,vh,n,vh,h,vh,n,n,n,xh,h,h,h,n,vh,h,n,l,h,n,42,605,1803,27.1],
      [h,h,h,vh,n,h,h,n,n,n,n,n,n,n,n,n,n,n,n,vl,h,vl,23,230,1271,14.2],
      [h,h,h,vh,vl,vl,l,vh,n,n,n,vh,h,n,n,n,h,l,n,vl,h,n,13,82,2250,17.2],
      [h,h,h,vh,l,l,n,n,n,n,n,n,l,l,l,n,n,h,h,l,h,n,15,55,1004,15.8],
      [h,h,h,vh,l,l,l,vl,n,n,n,h,n,h,h,n,vh,n,n,vl,h,n,60,47,2883,20.3],
      [h,h,h,vh,n,n,n,h,n,n,n,n,l,vh,n,n,h,h,h,l,h,n,15,12,504,13.5],
      [h,h,h,vh,n,n,n,h,n,n,n,n,l,vh,vh,n,vh,n,h,vl,h,n,6.2,8,197,9.6],
      [h,h,h,vh,vl,n,l,vh,n,n,n,n,n,h,l,n,vh,n,n,vl,h,n,n,8,294,9.5],
      [h,h,h,vh,n,l,l,n,n,n,n,n,l,n,vh,n,vh,h,h,l,h,n,5.3,6,173,8.7],
      [h,h,h,vh,l,l,n,n,n,n,n,h,l,h,n,n,n,h,h,vl,h,n,45.5,45,2645,21.0],
      [h,h,h,vh,l,n,n,n,n,n,n,vh,l,h,n,n,n,h,h,vl,h,n,28.6,83,1416,18.9],
      [h,h,h,vh,vl,l,n,n,n,n,n,vh,l,n,n,n,n,h,h,vl,h,n,30.6,87,2444,20.5],
      [h,h,h,vh,l,l,n,n,n,n,n,h,l,n,n,n,n,h,h,vl,h,n,35,106,2198,20.1],
      [h,h,h,vh,l,l,n,n,n,n,n,h,l,n,h,n,n,h,h,vl,h,n,73,126,4188,25.1],
      [h,h,h,vh,vl,vl,l,vh,n,n,n,n,l,vh,vh,n,vh,l,l,vl,h,n,23,36,2161,15.6],
      [h,h,h,vh,vl,l,l,l,n,n,n,n,l,l,l,n,h,h,h,vl,h,n,464,1272,32002,53.4],
      [h,h,h,vh,n,n,n,l,n,n,n,n,n,vh,vh,n,n,l,n,l,h,n,91,156,2874,22.6],
      [h,h,h,vh,l,h,n,n,n,n,vh,vh,n,h,h,n,n,l,n,vl,h,n,24,176,1541,20.3],
      [h,h,h,vh,vl,l,n,n,n,n,n,n,n,l,vl,n,n,n,h,vl,h,n,10,122,1225,16.2],
      [h,h,h,vh,vl,l,l,l,n,n,n,h,h,n,n,n,n,l,l,vl,h,n,8.2,41,855,13.1],
      [h,h,h,vh,l,l,l,h,n,n,h,vh,vh,vh,vh,n,n,l,l,vl,h,l,5.3,14,533,9.3],
      [h,h,h,vh,n,n,l,n,n,n,n,h,h,n,n,n,vh,n,h,vl,h,n,4.4,20,216,10.6],
      [h,h,h,vh,vl,l,l,vl,n,n,n,n,l,h,l,n,vh,h,h,vl,h,n,6.3,18,309,9.6],
      [h,h,h,vh,vl,h,l,vh,n,n,vh,vh,n,h,n,n,h,l,l,vl,h,l,27,958,3203,21.1],
      [h,h,h,vh,vl,n,l,h,n,n,h,vh,vh,n,n,n,n,l,l,vl,h,vl,17,237,2622,16.0],
      [h,h,h,vh,n,vh,l,vh,n,n,xh,vh,n,vh,vh,n,vh,h,h,vl,h,n,25,130,813,20.9],
      [h,h,h,vh,n,n,l,h,n,n,n,h,n,n,n,n,n,n,n,vl,h,n,23,70,1294,18.2],
      [h,h,h,vh,vl,h,l,vh,n,n,h,h,n,h,h,n,l,l,l,vl,h,l,6.7,57,650,11.3],
      [h,h,h,vh,n,n,l,h,n,n,n,n,l,h,h,n,n,h,n,vl,h,n,28,50,997,16.4],
      [h,h,h,vh,n,l,l,vh,n,n,h,vh,h,n,vh,n,vh,vl,vl,vl,h,n,9.1,38,918,15.3],
      [h,h,h,vh,n,n,l,h,n,n,n,n,n,vh,h,n,vh,n,n,vl,h,n,10,15,418,11.6],
      ])

def maxwell(opt=options(),tunings=tunings()):
  vl=1;l=2;n=3;h=4;vh=5;xh=6;_=0
  return Thing(
    kloc = 25,
    effort = 26,
    names = ['Syear','App','Har','Dba','Ifc','Source','Telonuse',
    'Nlan','T01','T02','T03','T04','T05','T06',
    'T07','T08','T09','T10','T11','T12','T13',
    'T14','T15','Duration','Size','Time','Effort'],
    projects=[
    [92,2,2,1,2,2,0,3,4,3,5,3,3,3,4,5,4,5,4,4,4,4,5,16,647,8,7871],
      [93,2,2,1,2,2,0,3,2,3,3,3,3,3,2,2,4,3,4,4,4,4,4,5,130,9,845],
      [90,1,2,1,2,2,0,2,3,3,2,3,3,4,2,3,4,5,4,3,2,3,3,8,254,6,2330],
      [86,3,2,1,2,2,0,3,2,2,4,2,2,1,3,5,4,4,5,4,3,2,3,16,1056,2,21272],
      [88,2,2,1,2,2,0,2,3,3,3,4,3,3,4,3,4,4,3,4,5,4,4,12,383,4,4224],
      [92,2,3,1,2,2,1,4,2,3,3,3,3,3,2,2,4,4,4,4,4,5,4,12,345,8,2826],
      [87,2,2,1,2,2,0,2,4,3,5,4,3,2,3,5,5,5,3,4,4,2,3,27,209,3,7320],
      [86,2,2,1,2,2,0,1,2,3,3,2,2,2,4,5,4,3,3,3,3,2,3,24,366,2,9125],
      [87,2,4,2,2,1,0,2,4,3,3,2,1,2,4,5,3,2,2,2,3,4,2,54,1181,3,11900],
      [87,1,2,1,2,2,0,2,2,3,2,3,3,3,2,5,3,4,2,3,2,3,3,13,181,3,4300],
      [90,2,5,1,2,1,0,1,5,3,4,2,3,1,3,3,3,2,2,2,1,1,2,21,739,6,4150],
      [91,3,1,0,2,2,0,2,2,2,2,4,3,3,1,4,4,3,4,4,1,5,1,7,108,7,900],
      [90,3,5,0,2,2,0,3,2,3,3,4,2,2,2,4,4,3,5,3,3,4,2,10,48,6,583],
      [91,1,2,1,2,2,0,2,2,3,2,4,3,3,3,5,4,3,3,4,2,4,3,19,249,7,2565],
      [92,2,2,1,2,2,0,2,3,4,3,3,3,3,3,3,5,5,2,4,3,3,3,11,371,8,4047],
      [87,2,2,1,2,2,0,1,2,3,2,4,3,3,4,4,4,3,2,4,3,3,3,13,211,3,1520],
      [91,2,2,1,2,2,1,4,4,1,3,3,3,4,4,5,4,4,4,4,3,3,4,32,1849,7,25910],
      [89,2,2,1,2,2,1,4,4,3,4,3,4,4,5,4,5,4,5,5,3,1,4,38,2482,5,37286],
      [85,3,3,1,2,2,0,4,3,2,3,3,3,2,4,5,4,4,4,4,4,2,3,40,434,1,15052],
      [87,2,2,1,2,2,0,3,4,3,4,4,4,2,3,4,5,5,3,4,4,2,3,29,292,3,11039],
      [90,3,3,1,2,2,0,4,4,4,2,3,3,3,4,3,4,4,5,3,2,3,3,14,2954,6,18500],
      [91,2,3,1,2,2,0,1,4,3,2,4,3,3,4,4,5,4,3,4,2,4,3,14,304,7,9369],
      [89,2,5,1,2,1,0,1,4,3,2,3,2,3,2,4,4,4,2,2,3,3,3,28,353,5,7184],
      [92,2,2,1,2,2,1,4,2,2,2,4,3,3,4,4,5,5,5,4,2,2,4,16,567,8,10447],
      [91,2,2,1,2,2,1,3,4,3,4,3,3,3,3,3,4,4,3,3,2,3,3,13,467,7,5100],
      [87,2,2,1,2,2,0,3,4,3,3,4,3,3,4,5,4,4,4,4,4,2,4,45,3368,3,63694],
      [92,3,2,1,2,2,1,2,3,3,3,4,3,4,2,4,4,3,2,4,4,2,4,4,253,8,1651],
      [91,4,3,1,2,2,1,3,1,4,2,3,3,4,2,3,2,3,2,4,2,4,3,10,196,7,1450],
      [92,1,2,1,2,2,0,4,3,4,2,3,3,4,3,5,3,3,3,4,4,5,3,12,185,8,1745],
      [88,3,2,1,2,2,0,2,2,4,3,2,2,2,3,4,5,4,4,4,3,3,4,6,387,4,1798],
      [88,5,2,1,2,2,0,2,1,3,3,3,3,2,4,5,3,2,3,3,3,4,3,28,430,4,2957],
      [89,2,2,1,2,2,0,2,3,4,2,3,3,3,3,4,3,4,2,4,3,3,3,6,204,5,963],
      [88,2,2,1,2,2,0,1,3,3,3,4,3,3,2,3,4,2,3,4,2,4,3,6,71,4,1233],
      [91,1,3,1,1,1,0,3,4,2,4,3,5,3,4,5,5,4,3,5,4,4,5,6,840,7,3240],
      [90,2,3,1,1,1,0,4,4,2,4,3,5,3,5,3,5,5,4,5,3,4,5,11,1648,6,10000],
      [91,2,3,1,1,1,0,4,4,2,4,3,5,3,5,3,5,5,4,5,3,4,5,8,1035,7,6800],
      [85,3,2,1,2,2,0,1,3,3,4,2,3,2,3,4,3,3,3,4,4,3,3,22,548,1,3850],
      [91,3,3,1,2,2,1,3,4,3,4,4,4,3,3,4,4,4,5,5,4,3,4,31,2054,7,14000],
      [88,5,2,1,2,2,0,2,2,3,2,4,3,3,3,4,3,3,3,3,2,4,3,26,302,4,5787],
      [93,3,3,1,2,2,1,3,4,2,2,3,4,4,4,2,4,2,4,3,4,3,4,22,1172,9,9700],
      [91,1,5,1,1,2,0,1,3,3,3,2,2,3,3,3,4,3,3,4,4,4,3,7,253,7,1100],
      [92,2,2,1,2,2,0,2,3,4,2,4,3,3,3,3,5,5,3,3,2,3,3,14,227,8,5578],
      [92,2,2,1,2,2,0,3,4,3,3,3,3,3,2,3,4,3,3,4,3,3,3,6,59,8,1060],
      [91,1,2,1,2,2,1,4,3,3,4,4,4,4,3,4,4,3,5,4,3,2,3,6,299,7,5279],
      [89,3,2,1,2,2,0,1,3,3,3,4,3,3,3,3,5,3,4,4,3,2,4,15,422,5,8117],
      [90,2,5,1,2,1,0,3,4,4,3,5,4,4,5,3,4,4,3,5,2,4,4,9,1058,6,8710],
      [90,1,5,4,2,2,0,3,4,2,2,3,3,2,4,4,4,4,3,4,4,5,3,9,65,6,796],
      [88,3,3,1,2,2,0,3,5,5,3,3,2,3,4,5,5,4,4,4,3,4,4,26,390,4,11023],
      [90,2,2,1,2,2,0,2,4,4,2,3,4,3,2,2,3,3,3,3,2,4,4,13,193,6,1755],
      [91,1,2,1,2,2,1,4,4,3,2,3,3,3,3,3,4,3,4,4,4,3,3,28,1526,7,5931],
      [93,3,3,1,2,2,1,2,2,3,3,3,3,3,4,2,4,3,4,4,2,3,3,13,575,9,4456],
      [87,2,2,1,2,2,0,1,2,3,3,4,3,3,3,4,4,3,2,4,4,2,3,13,509,3,3600],
      [88,5,2,1,2,2,0,3,1,4,4,2,3,3,2,3,2,2,2,4,5,3,3,12,583,4,4557],
      [88,3,2,1,2,2,0,2,4,3,5,3,3,3,4,5,4,3,3,4,3,3,3,14,315,4,8752],
      [89,3,2,1,2,2,0,2,3,4,5,3,3,3,3,3,4,4,2,4,4,3,3,12,138,5,3440],
      [88,2,3,1,2,2,0,3,3,4,3,3,3,3,3,4,4,4,4,4,4,4,3,9,257,4,1981],
      [85,2,2,1,2,2,0,1,2,3,3,2,2,2,4,5,4,3,3,4,4,2,3,30,423,1,13700],
      [91,5,5,1,2,1,0,3,4,2,4,3,3,3,3,3,5,3,3,4,3,4,4,20,495,7,7105],
      [90,3,3,1,2,2,1,4,2,3,3,4,3,3,3,4,4,3,4,3,2,4,3,16,622,6,6816],
      [92,1,2,1,2,2,1,2,3,3,3,3,3,4,4,5,5,5,5,4,3,2,3,12,204,8,4620],
      [90,3,3,1,2,2,1,4,2,3,2,3,3,2,3,5,5,4,5,5,1,5,4,15,616,6,7451],
      [91,3,3,1,2,2,0,3,2,4,3,3,3,3,4,3,5,5,5,4,4,5,4,33,3643,7,39479]
    ]
    )

def sdiv(lst, tiny=3,cohen=0.3,
         num1=lambda x:x[0], num2=lambda x:x[1]):
  "Divide lst of (num1,num2) using variance of num2."
  #----------------------------------------------
  class Counts(): # Add/delete counts of numbers.
    def __init__(i,inits=[]):
      i.zero()
      for number in inits: i + number 
    def zero(i): i.n = i.mu = i.m2 = 0.0
    def sd(i)  : 
      if i.n < 2: return i.mu
      else:       
        return (max(0,i.m2)*1.0/(i.n - 1))**0.5
    def __add__(i,x):
      i.n  += 1
      delta = x - i.mu
      i.mu += delta/(1.0*i.n)
      i.m2 += delta*(x - i.mu)
    def __sub__(i,x):
      if i.n < 2: return i.zero()
      i.n  -= 1
      delta = x - i.mu
      i.mu -= delta/(1.0*i.n)
      i.m2 -= delta*(x - i.mu)    

  #----------------------------------------------
  def divide(this,small): #Find best divide of 'this'
    lhs,rhs = Counts(), Counts(num2(x) for x in this)
    n0, least, cut = 1.0*rhs.n, rhs.sd(), None
    for j,x  in enumerate(this): 
      if lhs.n > tiny and rhs.n > tiny: 
        maybe= lhs.n/n0*lhs.sd()+ rhs.n/n0*rhs.sd()
        if maybe < least :  
          if abs(lhs.mu - rhs.mu) >= small:
            cut,least = j,maybe
      rhs - num2(x)
      lhs + num2(x)    
    return cut,least
  #----------------------------------------------
  def recurse(this, small,cuts):
    cut,sd = divide(this,small)
    if cut: 
      recurse(this[:cut], small, cuts)
      recurse(this[cut:], small, cuts)
    else:   
      cuts += [(sd * len(this)/len(lst),this)]
    return cuts
  #---| main |-----------------------------------
  small = Counts(num2(x) for x in lst).sd()*cohen
  if lst: 
    return recurse(sorted(lst,key=num1),small,[])

def fss(d=coc81(),want=0.25):
  rank=[]
  for i in range(d.sfem):
    xs=sdiv(d.projects,
         num1=lambda x:x[i],
         num2=lambda x:x[d.effort])
    xpect = sum(map(lambda x: x[0],xs))
    rank += [(xpect,i)]
  rank = sorted(rank)
  keep = int(len(rank)*want)
  doomed= map(lambda x:x[1], rank[keep:])
  for project in d.projects:
    for col in doomed:
      project[col] = 3
  return d

def less(d=coc81(),n=2):
  skipped = 0
  names0 = d.names
  toUse,doomed = [],[]
  for v in Features.values():
    toUse += v[:n]
  for n,name in enumerate(names0):
    if n >= d.sfem:
      break
    if not has(name,toUse):
      doomed += [n]
  for project in d.projects:
    for col in doomed:
      project[col] = 3
  return d

def meanr(lst):
  total=n=0.00001
  for x in lst:
    if not x == None:
      total += x
      n += 1
  return total/n

def tothree(lst):
  below=lst[:2]
  above=lst[3:]
  m1 = meanr(below)
  m2=  meanr(above)
  below = [m1 for _ in below]
  above = [m2 for _ in above]
  return below + [lst[2]] + above

# splits vl, l, n, h, vh into below, n, above
def rr3(lst):
  #return lst 
  r = 1
  if lst[0]> 2 : r = 0
  def rr1(n): return round(x,r) if x else None
  tmp= tothree([rr1(x) for x in lst])
  return tmp

def rr5(lst):
  if lst[0] > 2:
    return [6,5,4,3,2,1]
  if lst[0] < 0:
    return [0.8, 0.9, 1, 1.1, 1.2, 1.3]
  return   [1.2,1.1,1,0.9,0.8,0.7]

def rrs5(d):
  for k in d: d[k] = rr5(d[k])
  return d

def rrs3(d):
  for k in d: d[k] = rr3(d[k])
  return d


def detune(m,tun=tunings()):
  def best(at,one,lst):
    least,x = 100000,None
    for n,item in enumerate(lst):
      if item:
        tmp = abs(one - item)
        if tmp < least:
          least = tmp
          x = n
    return x
  def detuned(project):
    for n,(name,val) in  enumerate(zip(m.names,project)):
      if n <= m.sfem:
        project[n] = best(n,val,tun[name]) + 1
    return project
  m.projects = [detuned(project) for 
                project in m.projects]
  for p in m.projects: print p
  return m


#########################################
# begin code

## imports
import random,math,sys
r    = random.random
any  = random.choice
seed = random.seed
exp  = lambda n: math.e**n
ln   = lambda n: math.log(n,math.e)
g    = lambda n: round(n,2)
def say(x):
  sys.stdout.write(str(x))
  sys.stdout.flush() 

def nl(): print ""
## classes
class Score(Thing):

  def run(self, want=None, **kw):
    if want is None:
      raise ValueError('want cannot be None')
    try:
      self.seen(self.estimator_func(**kw), want)
    except Exception, err:
      import traceback
      raise Exception("asdsa")


  def finalize(i) : 
    i.all = []
    i.residuals=[]
    i.raw=[]
    i.use=False
  def seen(i,got,want): 
    i.residuals += [abs(got - want)]
    i.raw += [got - want]
    tmp = i.mre(got,want)
    i.all += [tmp]
    return tmp
  def mar(i):
    return median(sorted(i.residuals))
    #return sum(i.residuals) / len(i.residuals)
  def sanity(i,baseline):  
    return i.mar()*1.0/baseline
  def mre(i,got,want): 
    return abs(got- want)*1.0/(0.001+want)
  def mmre(i): 
    return sum(i.all)*1.0/len(i.all)
  def medre(i): 
    return median(sorted(i.all))
  def pred(i,n=30):
    total = 0.0
    for val in i.all:
      if val <= n*0.01: total += 1
    return total*1.0/len(i.all) 

## low-level utils
def pretty(s):
  if isinstance(s,float):
    return '%.3f' % s
  else: return '%s' % s



def stats(l,ordered=False):
  if not ordered: l= sorted(l)
  p25= l[len(l)/4]
  p50= l[len(l)/2]  
  p75= l[len(l)*3/4]
  p100= l[-1]
  print p50, p75-p25, p100

## mode prep
def valued(d,opt,t=tunings()):
  for old in d.projects:
    for i,name in enumerate(d.names):
      if i <= d.sfem:
        tmp = old[i]
        if not isinstance(tmp,float):
          tmp  = old[i] - 1
          old[i] = round(t[name][tmp],opt.round)
  return d

####################################

def median(lst,ordered=False):
  if not ordered: lst= sorted(lst)
  n = len(lst)
  if n==0: return 0
  if n==1: return lst[0]
  if n==2: return (lst[0] + lst[1])*0.5
  if n % 2: return lst[n//2]
  n = n//2
  return (lst[n] + lst[n+1]) * 0.5

class Count:
  def __init__(i,name="counter"):
    i.name=name
    i.lo =    10**32
    i.hi= -1*10**32
    i._all = []
    i._also = None
  def keep(i,n):
    i._also= None
    if n > i.hi: i.hi = n
    if n < i.lo: i.lo = n
    i._all += [n]
  def centroid(i):return i.also().median
  def all(i): return i.also().all
  def also(i):
    if not i._also:
      i._all = sorted(i._all)
      if not i._all: 
        i._also = Thing(all=i._all,
                        median=0)
      else:
        i._also = Thing(all=i._all,
                      median=median(i._all))
    return i._also
  def norm(i,n):
    #return n
    return (n - i.lo)*1.0 / (i.hi - i.lo + 0.0001)

def clone(old,data=[]):
  return Model(map(lambda x: x.name,old.headers),
              data)

class Model:
  def __init__(i,names,data=[],indep=0):
    i.indep = indep
    i.headers = [Count(name) for name in names]
    i._also = None
    i.rows = []
    for row in data: i.keep(row)
  def centroid(i): return i.also().centroid
  def xy(i)      : return i.also().xy
  def also(i):
    if not i._also:
      xs, ys  = 0,0
      for row in i.rows:
        xs += row.x
        ys += row.y
      n = len(i.rows)+0.0001
      i._also=  Thing(
        centroid= map(lambda x: x.centroid(), 
                      i.headers),
        xy      = (xs/n, ys/n))
    return i._also
  def keep(i,row):
    i._also = None
    if isinstance(row,Row):
      content=row.cells
    else:
      content=row
      row = Row(cells=row)
    for cell,header in zip(content,i.headers):
      header.keep(cell)
    i.rows += [row]
   

class Row(Thing):
  def finalize(i):
    i.x = i.y = 0
  def xy(i,x,y):
    if not i.x:
      i.x, i.y = x,y 
  

def lo(m,x)     : return m.headers[x].lo
def hi(m,x)     : return m.headers[x].hi
def norm(m,x,n) : return m.headers[x].norm(n)

def cosineRule(z,m,c,west,east,slots):
  a = dist(m,z,west,slots)
  b = dist(m,z,east,slots)
  x= (a*a + c*c - b*b)/(2*c+0.00001) # cosine rule
  y= max(0,a**2 - x**2)**0.5
  return x,y

def fastmap(m,data,slots):
  "Divide data into two using distance to two distant items."
  one  = any(data)             # 1) pick anything
  west = furthest(m,one,data,slots)  # 2) west is as far as you can go from anything
  east = furthest(m,west,data,slots) # 3) east is as far as you can go from west
  c    = dist(m,west,east,slots)
  # now find everyone's distance
  lst = []
  for one in data:
    x,y= cosineRule(one,m,c,west,east,slots)
    one.xy(x,y)
    lst  += [(x, one)]
  lst = sorted(lst)
  wests,easts = [], []
  cut  = len(lst) // 2
  cutx = lst[cut][0]
  for x,one in  lst:
    what  = wests if x <= cutx else easts
    what += [one]
  return wests,west, easts,east,cutx,c

def dist(m,i,j,slots):
  "Euclidean distance 0 <= d <= 1 between decisions"
  d1,d2  = slots.what(i), slots.what(j)
  n      = len(d1)
  deltas = 0
  for d in range(n):
    n1 = norm(m, d, d1[d])
    n2 = norm(m, d, d2[d])
    inc = (n1-n2)**2
    deltas += inc
  return deltas**0.5 / n**0.5

def furthest(m,i,all,slots,
             init = 0,
             better = lambda x,y: x>y):
  "find which of all is furthest from 'i'"
  out,d= i,init
  for j in all:
    if not i == j:
      tmp = dist(m,i,j,slots)
      if better(tmp,d): out,d = j,tmp
  return out

def myCentroid(row,t):
  x1,y1=row.x,row.y
  out,d=None,10**32
  for leaf in leaves(t):
    x2,y2=leaf.m.xy()
    tmp = ((x2-x1)**2 + (y2-y1)**2)**0.5
    if tmp < d:
      out,d=leaf,tmp
  return out

def centroid2(row,t):
  x1,y1=row.x,row.y
  out=[]
  for leaf in leaves(t):
    x2,y2 = leaf.m.xy()
    tmp = ((x2-x1)**2 + (y2-y1)**2)**0.5
    out += [(tmp,leaf)]
  out = sorted(out)
  if len(out)==0:
    return [(None,None),(None,None)]
  if len(out) ==1:
    return out[0],out[0]
  else:
    return out[0],out[1]

    

def where0(**other):
  return Thing(minSize  = 10,    # min leaf size
               depthMin= 2,      # no pruning till this depth
               depthMax= 10,     # max tree depth
               b4      = '|.. ', # indent string
               verbose = False,  # show trace info?
               what    = lambda x: x.cells
   ).override(other)


def where(m,data,slots=None):
  slots = slots or where0()
  return where1(m,data,slots,0,10**32)

def where1(m, data, slots, lvl, sd0,parent=None):
  here = Thing(m=clone(m,data),
               up=parent,
               _west=None,_east=None,leafp=False)
  def tooDeep(): return lvl > slots.depthMax
  def tooFew() : return len(data) < slots.minSize
  def show(suffix): 
    if slots.verbose: 
      print slots.b4*lvl + str(len(data)) + suffix
  if tooDeep() or tooFew():
    show(".")
    here.leafp=True
  else:
    show("1")    
    wests,west, easts,east,cut,c = fastmap(m,data,slots)
    here.plus(c=c, cut=cut, west=west, east=east)
    sd1=Num("west",[slots.klass(w) for w in wests]).spread()
    sd2=Num("east",[slots.klass(e) for e in easts]).spread()
    goWest = goEast = True
    if lvl > 0:
      goWest = sd1 < sd0
      goEast = sd2 < sd0
    if  goWest:
      here._west = where1(m, wests, slots, lvl+1, sd1,here)
    if  goEast:
      here._east = where1(m, easts, slots, lvl+1, sd2,here)
  return here

def leaf(t,row,slots,lvl=1):
  if t.leafp: 
    return t
  else:
    x,_ = cosineRule(row, t.m, t.c,t.west,t.east,slots)
    return leaf(t._west if x <= t.cut else t._east,
                row,slots,lvl+1)

def preOrder(t):
  if t:
    yield t
    for kid in [t._west,t._east]:
      for out in preOrder(kid):
        yield out
      
def leaves(t):
  for t1 in preOrder(t):
    if t1.leafp:
      yield t1
          
def tprint(t,lvl=0):
  if t:
    print '|.. '*lvl + str(len(t.m.rows)), '#'+str(t._id)
    tprint(t._west,lvl+1)
    tprint(t._east,lvl+1)

import sys,math,random
sys.dont_write_bytecode = True

def go(f):
  "A decorator that runs code at load time."
  print "\n# ---|", f.__name__,"|-----------------"
  if f.__doc__: print "#", f.__doc__
  f()

# random stuff
seed = random.seed
any  = random.choice

# pretty-prints for list
def gs(lst) : return [g(x) for x in lst]
def g(x)    : return float('%.4f' % x) 
"""

### More interesting, low-level stuff

"""
def timing(f,repeats=10):
  "How long does 'f' take to run?"
  import time
  time1 = time.clock()
  for _ in range(repeats):
    f()
  return (time.clock() - time1)*1.0/repeats

def showd(d):
  "Pretty print a dictionary."
  def one(k,v):
    if isinstance(v,list):
      v = gs(v)
    if isinstance(v,float):
      return ":%s %g" % (k,v)
    return ":%s %s" % (k,v)
  return ' '.join([one(k,v) for k,v in
                    sorted(d.items())
                     if not "_" in k])




####################################

## high-level business knowledge
def effort(d,project, a=2.94,b=0.91):
  "Primitive estimation function"
  def sf(x) : return x[0].isupper()
  sfs , ems = 0.0, 1.0
  kloc = project[d.kloc]
  i = -1
  for name,val in zip(d.names,project):
    i += 1
    if i > d.sfem : break
    if sf(name):
      sfs += val 
    else:
      ems *=  val
  return a*kloc**(b + 0.01*sfs) * ems

def cart(train,test,most, **kwargs):
  from sklearn import tree
  indep = map(lambda x: x[:most+1], train)
  dep   = map(lambda x: x[most+1],  train)
  t = tree.DecisionTreeRegressor(**kwargs).fit(indep,dep)
  return t.predict(test[:most+1])[0]

def bayesian_ridge(train,test,most, **kwargs):
  from sklearn import linear_model
  indep = map(lambda x: x[:most+1], train)
  dep   = map(lambda x: x[most+1],  train)
  for k in ('opt', 'them', 'project', 'model', 'random_state'):
    try:
      del kwargs[k]
    except KeyError:
      pass
  t = linear_model.BayesianRidge(n_iter=1000, normalize=True, **kwargs).fit(indep,dep)
  # t = linear_model.BayesianRidge(**kwargs).fit(indep,dep)
  # return t.predict(test[:most+1])[0]
  return t.predict(test[:most+1])

verbose_names= ['Prec', 'Flex', 'Resl', 'Team', 'Pmat', 'rely', 'data', 'cplx', 'ruse',
     'docu', 'time', 'stor', 'pvol', 'acap', 'pcap', 'pcon', 'aexp', 'plex',  
     'ltex', 'tool', 'site', 'sced', 'kloc', 'effort', '?defects', '?months']
def verbose_cart(train,test,most, **kwargs):
  from sklearn.tree import DecisionTreeRegressor
  indep = map(lambda x: x[:most+1], train)
  dep   = map(lambda x: x[most+1],  train)
  t = DecisionTreeRegressor(**kwargs).fit(indep,dep)
  print '%', kwargs
  print zip(verbose_names, t.feature_importances_)
  return t.predict(test[:most+1])[0]

successful_fits = 0

def forest(train,test,most, **kwargs):
  # print "+ =============================================="
  # print len(train)
  # print len(test)
  # print most
  # print kwargs
  # print
  # print "- =============================================="
  # raise Exception("I know")
  global successful_fits
  from sklearn.ensemble import RandomForestRegressor
  #print "blah"
  indep = map(lambda x: x[:most+1], train)
  dep   = map(lambda x: x[most+1],  train)
  #print "boom"
  try:
    del kwargs['splitter']
  except KeyError:
    pass
  try:
    del kwargs['opt']
  except KeyError:
    pass
  #print kwargs
  try:
    rf = RandomForestRegressor(n_jobs=-1, **kwargs).fit(indep,dep)
  except:
    import traceback
    traceback.print_exc()
  # successful_fits += 1
  #print '%xxxxxxxxxxxxxxxxxxxxxx', 'fit', str(successful_fits)
  temp = rf.predict(test[:most+1])[0]
  #print ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ",temp
  return temp

def get_forest(**kwargs):
  def forest_inner(train, test, most, **ignore):
    return forest(train, test, most, **kwargs)
  return forest_inner

def forest_with_trees(n_estimators):
  def forest_with_trees_inner(train, test, most, **kwargs):
    return forest(train, test, most, n_estimators=n_estimators)
  return forest_with_trees_inner

string_dealios = {'splitter': ('best', 'random')}
# ignoring max_depth, varying min_samples_leaf instead
# min_samples_leaf: stays at 1 for small datasets
# compute_importances: maybe later
int_dealios = {'min_samples_split': (1, 100),
               'max_leaf_nodes': (2, 100)}
# float_dealios = {'min_density': (0,1)}

def get_carts(splitter, min_samples_split, max_leaf_nodes):
  # using a wrapper instead of partial because the rig is gross and we need
  # to ignore uncaptured kwargs
  def partial_cart(train, test, most, **kw):
    return cart(train, test, most,
                splitter=splitter,
                min_samples_split=min_samples_split,
                max_leaf_nodes=max_leaf_nodes)
  return partial_cart


def get_rand_cart(string_dealios=string_dealios, int_dealios=int_dealios):
  '''
  some kinda magic up in here
  '''

  ivs = {}
  for k, v in string_dealios.iteritems():
    ivs[k] = IV(valid_inputs=v)
  for k, v in int_dealios.iteritems():
    ivs[k] = IV(lo=min(v), hi=max(v), gen_type=int)

  def rand_cart(train, test, most, **kw):
    return min([cart(train, test, most,
                **{k: v() for k, v in ivs.iteritems()}) for _ in range(1000)])

  return rand_cart


def get_knn_estimator(k):
  '''
  returns a closure that calculates knn for the given k
  '''
  @show_params
  def knn_estimator(model, them, project, opt, **kw):
    # ignore excess kwargs. Don't judge me
    return knn(model(), them, project, opt, k)
  knn_estimator.__name__ += '_{}'.format(str(k))
  return knn_estimator


def nc(n):
  return True #say(chr(ord('a') + n))
def loo(s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,
        s12,s13,s14,s15,s16,s17,s18,s19,s20,s21,s22,s23,s24,s25,s26,
        s27,s28,s29,s30,s31,s32,s33,s34,s35,s36,s37,s38,s39,s40,s41,
        s42,s43,s44,s45,s46,s47,s48,s49,
        score_list,
        model=nasa93,t=tunings(),opt=None,detuning=True, seed=1):
  "Leave one-out"
  if opt == None: opt=options()
  d= model(opt)
  for i,project in enumerate(d.projects):
    import sys
    sys.stderr.write(str(i)); sys.stderr.flush()
    #print ">>>>>>>>>>>",len(project),d.effort
    want = project[d.effort]
    them = d.projects[:i] + d.projects[i+1:]
    for s in score_list:
      import time
      #print '% start:', time.time()
      # print '%', s
      try:
        #print "+++++++++++++++++++++++++ ",want,model,
        s.run(want=want, model=model, them=them, project=project, opt=opt,
              train=them, test=project, most=d.kloc, random_state=seed)
        #print '% end:', time.time()
      except AttributeError:
        raise Exception("Something wrong")
        pass

    # 
    if s15.use:
      nc(15)
      got15=knn(model(),them,project,opt,5); s15.seen(got15,want)

    if s16.use:
      nc(16)
      got16=knn(model(),them,project,opt,3); s16.seen(got16,want)
    if s17.use:
      nc(17)
      got17=knn(model(),them,project,opt,1); s17.seen(got17,want)
    #say(0)
    if s5.use or s7.use: 
      nc(5)
      got5,got7  = vasil(model,them,project); s5.seen(got5,want); s7.seen(got7,want)
    #say(1)
    if s1.use:
      nc(1)
      got1  = wildGuess(d,them,opt); s1.seen(got1,want)
    #say(2)
    if s4.use:
      nc(4)
      got4  = cart(them, project,d.kloc); s4.seen(got4,want)
    #say(5)
    if s8.use:
      nc(8)
      got8  = loc(d,them,project,3);     s8.seen(got8,want)
    if s18.use:
      nc(18)
      got18 = loc(d,them,project,1);     s18.seen(got18,want)
    #say(6)
    if s9.use or s10.use or s19.use or s20.use or s21.use or s22.use:
      project1 = project[:]
      project1[d.kloc]=0
      them1=[]
      for one in them: 
        tmp=one[:]
        tmp[d.kloc]=0
        them1 += [tmp]
      if s9.use or s10.use:
        nc(9)
        got9,got10  = vasil(model,them1,project1);
        s9.seen(got9,want); s10.seen(got10,want)
      if s19.use:
        nc(19)
        got19=knn(model(),them1,project1,opt,5); s19.seen(got19,want)
      if s20.use:
        nc(20)
        got20=knn(model(),them1,project1,opt,3); s20.seen(got20,want)
      if s21.use:
        nc(21)
        got21=knn(model(),them1,project1,opt,1); s21.seen(got21,want)
      if s22.use:
        nc(22)
        got22=cart(them1, project1,d.kloc);s22.seen(got22,want)

  if s2.use or s3.use:
    d= model(opt)
    d = valued(d,opt)
    for i,project in enumerate(d.projects):     
      want = project[d.effort]
      them = d.projects[:i] + d.projects[i+1:]
      if s2.use:
        nc(2)
        got2 = effort(d,project,2.94,0.91);   s2.seen(got2,want)
      if s3.use:
        nc(3)
        a,b  = coconut(d,them,opt);           
        got3 = effort(d,project,a,b);          s3.seen(got3,want)

  if s11.use or s12.use:
    #if not detuning: return True
    t=rrs3(tunings())
    d=model()
    d = valued(d,opt,t=t)
    for i,project in enumerate(d.projects):
      want= project[d.effort]
      them= d.projects[:i] + d.projects[i+1:]
    #say(7)
      if s11.use:
        nc(11)
        got11=effort(d,project,2.94,0.91); s11.seen(got11,want)
      if s12.use:
        nc(12)
        a,b=coconut(d,them,opt)
    #say(8)
        got12= effort(d,project,a,b); s12.seen(got12,want)
  if s23.use or s24.use or s25.use or s26.use:
     t = rrs3(tunings())
     d = model()
     d = valued(d,opt,t=t)
     for i,project in enumerate(d.projects):
       want= project[d.effort]
       them= d.projects[:i] + d.projects[i+1:]
       for n,s in [(8,s23), (12,s24), (16,s25),(4,s26)]:
         nc(23)
         them = shuffle(them)[:n]
         a,b = coconut(d,them,opt)
         got = effort(d,project,a,b); s.seen(got,want)
  if s27.use or s28.use or s29.use:
     for n,s in [(1,s27),(2,s28),(3,s29)]:
       t = rrs3(tunings())
       d = model()
       d = less(d,n)
       d = valued(d,opt,t=t)
       for i,project in enumerate(d.projects):
         nc(28)
         want= project[d.effort]
         them= d.projects[:i] + d.projects[i+1:]
         a,b = coconut(d,them,opt)
         got = effort(d,project,a,b); s.seen(got,want)
  if s30.use or s31.use or s32.use or s33.use or s34.use or s35.use or s36.use or s37.use or s38.use or s39.use or s40.use or s41.use:
     for n1,n2,s in [(0.25,4,s30),(0.25,8,s31),(0.25,12,s32),(0.25,16,s33),
                     (0.5, 4,s34),(0.5, 8,s35),(0.5, 12,s36),(0.5, 16,s37),
                     (1,4,s38),(1,8,s39),(1,12,s40),(1,16,s41)]:
       t = rrs3(tunings())
       d = model()
       d.projects = shuffle(d.projects)[:n2]
       d = fss(d,n1)
       d = valued(d,opt,t=t)
       for i,project in enumerate(d.projects):
         nc(36)
         want= project[d.effort]
         them= d.projects[:i] + d.projects[i+1:]
         a,b = coconut(d,them,opt)
         got = effort(d,project,a,b); s.seen(got,want)
    
  if  s13.use or s14.use:
    t=rrs5(tunings())
    d=model()
    d = valued(d,opt,t=t)
    for i,project in enumerate(d.projects):
      want= project[d.effort]
      them= d.projects[:i] + d.projects[i+1:]
    #say(9)
      if s13.use:
        nc(13)
        got13=effort(d,project,2.94,0.91); s13.seen(got13,want)
      if s14.use:
        nc(14)
        a,b=coconut(d,them,opt)
    #say("+")
        got14= effort(d,project,a,b); s14.seen(got14,want)

  if s42.use or s43.use or s44.use or s45.use or s46.use or s47.use or s48.use or s49.use:
     n1 = 0.5
     n2 = 8
     for noise,(carts,cocs,nuts,nears) in [
         (.25, (  s42, s44, s46, s48)),
         (.5, (  s43,  s45,s47, s49))
         ]:
       t = rrs3(tunings())
       d = model()
       d.projects = shuffle(d.projects)[:n2]
       d = fss(d,n1)
       d = valued(d,opt,t=t)
       for project in d.projects:
           old = project[d.kloc]
           new = old * ((1 - noise) + 2*noise*random.random())
           project[d.kloc]= new
       for i,project in enumerate(d.projects):
         nc(42)
         want= project[d.effort]
         them= d.projects[:i] + d.projects[i+1:]
         a,b=coconut(d,them,opt)
         nuts.seen(effort(d,project,a,b)      ,want)
         carts.seen(cart(them, project,d.kloc),want)
         cocs.seen(effort(d,project)          ,want)
        
         

def loc(d,them,project,n):
  me = project[d.kloc]
  all= sorted([(abs(me-x[d.kloc]),x[d.effort]) for x in them])
  one = two = three = four = five = all[0][1]
  if len(them) > 1: two = all[1][1]
  if len(them) > 2: three=all[2][1]
  if len(them) > 3: four=all[3][1]
  if len(them) > 4: five=all[4][1]
  # look at that: mean works as well as triangular kernel
  if n == 1 : return one
  if n == 2 : return (one *2 + two*1)/3
  if n == 3 : return  (one*3 + two*2+ three*1)/6
  if n == 4 : return (one * 4 + two * 3 + three * 2  + four * 1)/10
  return (one*5 + two*4 + three*3 + four*2 + five*1)/15
#  if n == 1 : return one
#  if n == 2 : return (one *1 + two*1)/2
#  if n == 3 : return  (one*1 + two*1+ three*1)/3
#  if n == 4 : return (one * 1 + two * 1 + three * 1  + four * 1)/4
#  return (one*1 + two*1 + three*1 + four*1 + five*1)/5

def walk(lst):
  lst = sorted([(median(x[1].all),x[0],x[1].all) for x in lst])
  say( lst[0][1])
  walk1(lst[0],lst[1:])
  print ""

def walk1(this,those):
  if those:
    that=those[0]
    _,n1=this[1], this[2]
    w2,n2=that[1], that[2]
    if mwu(n1,n2) :
      say(" < "+ str(w2))
      walk1(that,those[1:])
    else:
      say(" = " + str(w2))
      walk1(("","",n1+n2),those[1:])

def a12slow(lst1,lst2,rev=True):
  "how often is x in lst1 more than y in lst2?"
  more = same = 0.0
  for x in lst1:
    for y in lst2:
      if   x==y : same += 1
      elif rev     and x > y : more += 1
      elif not rev and x < y : more += 1
  x= (more + 0.5*same) / (len(lst1)*len(lst2))
  #if x > 0.71: return g(x),"B"
  #if x > 0.64: return g(x),"M"
  return x> 0.6 #g(x),"S"

def a12cmp(x,y):
  if y - x > 0 : return 1
  if y - x < 0 : return -1
  else: return 0

a12s=0
def a12(lst1,lst2, gt= a12cmp):
  "how often is x in lst1 more than y in lst2?"
  global a12s
  a12s += 1
  def loop(t,t1,t2): 
    while t1.j < t1.n and t2.j < t2.n:
      h1 = t1.l[t1.j]
      h2 = t2.l[t2.j]
      h3 = t2.l[t2.j+1] if t2.j+1 < t2.n else None 
      if gt(h1,h2) < 0:
        t1.j  += 1; t1.gt += t2.n - t2.j
      elif h1 == h2:
        if h3 and gt(h1,h3) < 0:
            t1.gt += t2.n - t2.j  - 1
        t1.j  += 1; t1.eq += 1; t2.eq += 1
      else:
        t2,t1  = t1,t2
    return t.gt*1.0, t.eq*1.0
  #--------------------------
  lst1 = sorted(lst1, cmp=gt)
  lst2 = sorted(lst2, cmp=gt)
  n1   = len(lst1)
  n2   = len(lst2)
  t1   = Thing(l=lst1,j=0,eq=0,gt=0,n=n1)
  t2   = Thing(l=lst2,j=0,eq=0,gt=0,n=n2)
  gt,eq= loop(t1, t1, t2)
  #print gt,eq,n1,n2
  return gt/(n1*n2) + eq/2/(n1*n2)


class Counts(): # Add/delete counts of numbers.
  def __init__(i,inits=[]):
    i.n = i.mu = i.m2 = 0.0
    for number in inits: i + number 
  def sd(i) : 
    if i.n < 2: return i.mu
    else:       
      return (i.m2*1.0/(i.n - 1))**0.5
  def __add__(i,x):
    i.n  += 1
    delta = x - i.mu
    i.mu += delta/(1.0*i.n)
    i.m2 += delta*(x - i.mu)
  
def wildGuess(d,projects,opt):
  tally = 0
  for _ in xrange(opt.guesses):
    project = any(projects)
    tally += project[d.effort]
  return tally*1.0/opt.guesses

def run_de_cart(train, test, most, **kw):
  s = DifferentialEvolution(partial(CARTModel, train, test, most))
  return s.run().best

def run_pso_cart(train, test, most, **kw):
  s = ParticleSwarmOptimizer(partial(CARTModel, train, test, most))
  return s.run().best

def run_de_forest(train, test, most, **kw):
  s = DifferentialEvolution(partial(RFModel, train, test, most))
  return s.run().best

def run_pso_forest(train, test, most, **kw):
  s = ParticleSwarmOptimizer(partial(RFModel, train, test, most))
  return s.run().best

def get_de_verbose_cart(n):
  def run_de_verbose_cart(train, test, most, **kw):
    s = DifferentialEvolution(partial(VerboseCARTModel, n, train, test, most))
    return s.run().best
  return run_de_verbose_cart

def coconut(d,tests,opt,lvl=None,err=10**6,
            a=10,b=1,ar=10,br=0.5):
  "Chase good  a,b settings"
  #return 2.94,0.91
  def efforts(a,b):
    s=Score()
    for project in tests:
      got = effort(d,project,a,b)
      want = project[d.effort]
      s.seen(got,want)
    return s.mmre()
  if lvl == None: lvl=opt.levels
  if lvl < 1 : return a,b
  old = err
  for _ in range(opt.samples):
    a1 = a - ar + 2*ar*r()
    b1 = b - br + 2*br*r()
    tmp = efforts(a1,b1)
    if tmp < err:
      a,b,err = a1,b1,tmp
  if (old - err)/old < opt.epsilon:
    return a,b
  else:
    return coconut(d,tests,opt,lvl-1,err, a=a,b=b,
                   ar=ar*opt.shrink,
                   br=br*opt.shrink)

## sampple main
def main(model=nasa93):
  xseed(1)
  for shrink in [0.66,0.5,0.33]:
    for sam in [5,10,20]:
      for lvl in [5,10,20]:
        for rnd in [0,1,2]:
          opt=options()
          opt.shrink=shrink
          opt.samples=sam
          opt.round = rnd
          opt.levels = lvl
          loo(model=model,opt=opt)


#########################################
# start up code


def mwu(l1,l2):
  import numpy as np
  from scipy.stats import  mannwhitneyu
  #print "l1>",map(g,sorted(l1))
  #print "l2>",map(g,sorted(l2))
  _, p_value =  mannwhitneyu(np.array(l1), 
                             np.array(l2))
  return p_value <= 0.05

# for e in [1,2,4]:
#   print "\n"
#   l1 = [r()**e for _ in xrange(100)]
#   for y in [1.01,1.1,1.2,1.3,1.4, 1.5]:
#     l2 = map(lambda x: x*y,l1)
#     print e,y,mwu(l1,l2)

def test1(lst,repeats=10,models=[coc81],what='locOrNot'):
  #seed(1)
  #print repeats,what,map(lambda x:x.__name__,models)
#for m in [ newCIIdata, xyz14,nasa93,coc81]:
  import time
  detune=False
  for m  in models:  
      print ">>>>>>>>>>>>>>>>>>>",m
     #(newCIIdataDeTune,True),#, #, 
#     (xyz14deTune,True)
 #    #(coc81,True),
     #(nasa93,True)
  #  ]:
      s1=Score();  s2=Score(); s3=Score(); s4=Score();
      s5=Score();  s6=Score(); s7=Score(); s8=Score()
      s9=Score();  s10=Score(); s11=Score(); s12=Score();
      s13=Score(); s14=Score();
      s15=Score();  s16=Score(); s17=Score(); s18=Score()
      s19=Score();  s20=Score(); s21=Score();
      s22=Score()
      s23=Score()
      s24=Score(); s25=Score(); s26=Score()
      s27=Score(); s28=Score(); s29=Score()
      s30=Score(); s31=Score(); s32=Score()
      s33=Score(); s34=Score(); s35=Score()
      s36=Score(); s37=Score(); s38=Score()
      s39=Score(); s40=Score(); s41=Score()

      s42=Score(); s43=Score(); s44=Score()
      s45=Score(); s46=Score(); s47=Score()
      s48=Score(); s49=Score();
      # loc or no loc
      # exps =dict(locOrNot = [("coc2000",s2),("coconut",s3),
      #                        ("loc(3)",s8), ("loc(1)",s18), 
      #                        #('knear(3)',s16),  ("knear(3) noloc",s20),
      #                        #('knear(1)',s17),("knear(1) noloc",s21) 
      #                        ],
      #            basicRun = [("coc2000",s2),("coconut",s3),
      #                        ('knear(3)',s16),('knear(1)',s17),
      #                        #("cluster(1)",s5),
      #                        ("cluster(2)",s7),   
      #                        ("cart",s4)],
      #            qualitative= [("coc2000",s2),("coconut",s3),
      #                          #('knear(3)',s16),('knear(1)',s17),
      #                          ("coco2000(simp)",s13), ("coconut(simp)",s14),
      #                          ("coco2000(lmh)",s11), ("coconut(lmh)",s12)],
      #            other    =  [('(c=1)n-noloc',s9),('(c=2)n-noloc',s10)],
      #            less     = [("coc2000",s2),("coconut",s3),
      #                        ("coco2000(lmh)",s11), ("coconut(lmh)",s12),
      #                        ('coconut(lmh8)',s23),('coconut(lmh12)',s24), 
      #                        ('coconut(lmh16)',s25),
      #                        ('coconut(lmh4)',s26)],
      #            lessCols = [("coc2000",s2),("coconut",s3),
      #                        ('coconut(just5)',s27),
      #                        ('coconut(just10)',s28),
      #                        ('coconut(just15)',s29)],
      #            fssCols = [("coc2000",s2),("coconut",s3),
      #                       ('coconut:c*0.25,r=4',s30),
      #                       ('coconut:c*0.25,r=8',s31),
      #                       #('coconut:c*0.25,r=12',s32),
      #                       #('coconut:c*0.25,r=16',s33),
      #                       ('coconut:c*0.5,r=4',s34),
      #                       ('coconut:c*0.5,r=8',s35),
      #                       #('coconut:c*0.5,r=12',s36),
      #                       #('coconut:c*1,r=16',s37),
      #                       ('coconut:c*1,r=4',s38),
      #                       ('coconut:c*1,r=8',s39),
      #                       #('coconut:c*1,r=12',s40),
      #                       #('coconut:c*1,r=16',s41)
      #                     ],
      #             noise = [  ("cart",s4),               ("cart/4",s42),               ("cart/2",s43),         
      #                        ("coc2000",s2),            ("coc2000n/4",s44),           ("coc2000n/2",s45),
      #                        ('coconut:c*0.5,r=8',s35), ('coconut:c*0.5r=8n/4',s46) , ('coconut:c*0.5,r=8n/2',s47),
      #                        ('knear(1)',s17),          ('knear(1)/4',s48),           ('knear(1)/2',s49)
      #                      ],
      #             knnOnly = [
      #               ('knear(3)',s16),('knear(1)',s17),
      #             ],
      #             knnOnlyNew = [
      #                       ('knear({})'.format(n+1), Score(estimator_func=get_knn_estimator(n+1)))
      #                        for n in range(10)
      #                      ],
      #             cartRand = [
      #               ('cart_rand', Score(estimator_func=get_rand_cart()))
      #             ],
      #             cartComponents = [
      #               ('cartcomponents',
      #                Score(estimator_func=get_de_verbose_cart(len(m().projects) - 1)))
      #             ],
      #             allTheCart = [
      #               ('cart({0}, {1}, {2})'.format(splitter,
      #                                             min_samples_split,
      #                                             max_leaf_nodes),
      #                Score(estimator_func=get_carts(splitter,
      #                                               min_samples_split,
      #                                               max_leaf_nodes)))
      #                for splitter, min_samples_split, max_leaf_nodes in
      #                    product(('best', 'random'),
      #                            (2**n for n in range(0, 10)),
      #                            (2**n for n in range(0, 10)))
      #             ],
      #             search = [
      #               ('de(cart)', Score(estimator_func=run_de_cart)),
      #               # ('de(rf)', Score(estimator_func=run_de_forest)),
      #               ("coc2000",s2),("coconut",s3),
      #               ('knear(3)',s16),('knear(1)',s17),
      #               ("cart",s4)
      #             ],
      #             forestOnly = [
      #               ('forest({} trees)'.format(n),
      #                Score(estimator_func=forest_with_trees(n)))
      #                for n in (150,)
      #             ] + [('de(cart)', Score(estimator_func=run_de_cart)),
      #                  ('de(rf)', Score(estimator_func=run_de_forest))],
      #             deKNN = [
      #               ('de(knn)', Score(estimator_func=run_de_knn))
      #             ],
      #             bayesianRidge = [
      #               ('ridge', Score(estimator_func=bayesian_ridge))
      #             ],
      #             dePsoCart = [
      #               ('de(cart)', Score(estimator_func=run_de_cart)),
      #               ('pso(cart)', Score(estimator_func=run_pso_cart)),
      #             ],
      #             forestTuned = [
      #               ('forest(mss={},msl={})'.format(x, y),
      #                Score(estimator_func=get_forest(min_samples_split=x, min_samples_leaf=y, n_estimators=100, max_features="sqrt")))
      #                for x, y in product((2**n for n in range(5)), (2**n for n in range(5)))
      #             ],
      #             shootout = [
      #               # ('de(cart)', Score(estimator_func=run_de_cart)),
      #               # # ('de(rf)', Score(estimator_func=run_de_forest)),
      #               # ("coc2000",s2),("coconut",s3),
      #               # ('knear(3)',s16),('knear(1)',s17),
      #               # ("cart",s4),
      #               ('forest(mss=1,msl=2)',
      #                Score(estimator_func=get_forest(min_samples_split=1,
      #                                                min_samples_leaf=2,
      #                                                n_estimators=150))),
      #               ('forest(mss=2,msl=1)',
      #                Score(estimator_func=get_forest(min_samples_split=2,
      #                                                min_samples_leaf=1,
      #                                                n_estimators=150)))
      #             ]
      #            )
      # lst = exps[what]
      # for x in lst:
      #   print x
      #   print
      # raise Exception("I am here")
      print '%',what
      for _,s in lst: s.use=True
      t1=time.clock()
      import sys
      
      #say("%")
      # print "Repeat: >>>>>>>>>>>>>>>>>>>>>>> ",repeats
      for i in range(repeats):
        sys.stderr.write(str(i)); sys.stderr.flush()
        say(' ' + str(i))
        loo(s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12,s13,
            s14,s15,s16,s17,s18,s19,s20,s21,s22,s23,s24,s25,s26,
             s27,s28,s29,s30,s31,s32,
            s33,s34,s35,s36,s37,s38,s39,s40,s41,s42,s43,s44,s45,s46,s47,s48,s49,
            score_list=tuple(x[1] for x in lst),
            # score_list=[],
            model=m,detuning=detune, seed=i)
      # global bs
      # global a12s
      # bs = a12=0
      # t2 = time.clock()
      # print "="
      # # for x in lst:
      # #   print x[1]

      assert(len(lst) == 1 ),"wrong1"
      return lst[0][1].all
      # print "Score>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> : ",lst
      # rdivDemo([[x[0]] + x[1].all for x in lst if x[1].all])
      # t3 = time.clock()
      # print "\n :learn",t2-t1,":analyze",t3-t2,":boots",bs,"effects",a12s,":conf",0.99**bs
      
#print 'B>', bootstrap([1,2,3,4,5],[1,2,3,4,5])

@show_params
def knn(src,them,project,opt,k):
  slots = where0(what= lambda x:cocVals(x,src.effort))
  m0=Model(src.names,src.projects)
  m1=clone(m0,them)
  w = [None]*k
  ws = 0
  for i in range(k): ws += i+1
  for i in range(k): w[i] = (i+1)/ws
  w.reverse()
  #w = [1/k]*k
  
  dists =[(dist(m1,Row(cells=that),Row(cells=project),slots),that[src.effort])
          for that in them]
  est = 0
  for w1,(_,x) in zip(w,sorted(dists)[:k]):
    est += w1*x
  return est

def cocVals(row,n):
  if isinstance(row,Row):
    row=row.cells
  return row[:n]

def vasil(src,data,project):
  all = src()
  m0 = Model(all.names,all.projects)
  m1 = clone(m0,data)
  e  = all.effort
  slots = where0(what= lambda x:cocVals(x,e)
                 ,klass=lambda x:x.cells[all.effort])
  t     = where(m1,m1.rows,slots)
  row = Row(cells=project)
  got1 = got2 = Num(slots.klass(r) for r in data).median()
  (d1,c1),(d2,c2) = centroid2(row,t)
  if c1 or c2:
    w1,w2 = 1/(d1+0.0001), 1/(d2+0.0001)
    e1 = c1.m.centroid()[e]
    e2 = c2.m.centroid()[e]
    got2 = (w1*e1 + w2*e2) / (w1+w2)
    got1=myCentroid(row,t).m.centroid()[e]
  #got1b=leaf(t,row,slots).m.centroid()[e]
  return got1,got2

class Num:
  "An Accumulator for numbers"
  def __init__(i,name,inits=[]): 
    i.n = i.m2 = i.mu = 0.0
    i.all=[]
    i._median=None
    i.name = name
    i.rank = 0
    for x in inits: i.add(x)
  def s(i)       : return (i.m2/(i.n - 1))**0.5
  def add(i,x):
    i._median=None
    i.n   += 1   
    i.all += [x]
    delta  = x - i.mu
    i.mu  += delta*1.0/i.n
    i.m2  += delta*(x - i.mu)
  def __add__(i,j):
    return Num(i.name + j.name,i.all + j.all)
  def quartiles(i):
    def p(x) : return int(100*g(xs[x]))
    i.median()
    xs = i.all
    n  = int(len(xs)*0.25)
    return p(n) , p(2*n) , p(3*n)
  def median(i):
    if not i._median:
      i.all = sorted(i.all)
      i._median=median(i.all)
    return i._median
  def __lt__(i,j):
    return i.median() < j.median() 
  def spread(i):
    i.all=sorted(i.all)
    n1=i.n*0.25
    n2=i.n*0.75
    if len(i.all) <= 1:
      return 0
    if len(i.all) == 2:
      return i.all[1] - i.all[0]
    else:
      return i.all[int(n2)] - i.all[int(n1)]


def different(l1,l2):
  #return bootstrap(l1,l2) and a12(l2,l1)
  return a12(l2,l1) and bootstrap(l1,l2)


def scottknott(data,cohen=0.3,small=3, useA12=False,epsilon=0.01):
  """Recursively split data, maximizing delta of
  the expected value of the mean before and 
  after the splits. 
  Reject splits with under 3 items"""
  #data = [d for d in data if d.spread() < 0.75]
  all  = reduce(lambda x,y:x+y,data)
  #print sorted(all.all)
  same = lambda l,r: abs(l.median() - r.median()) <= all.s()*cohen
  if useA12: 
    same = lambda l, r:   not different(l.all,r.all) 
  big  = lambda    n: n > small    
  return rdiv(data,all,minMu,big,same,epsilon)

def rdiv(data,  # a list of class Nums
         all,   # all the data combined into one num
         div,   # function: find the best split
         big,   # function: rejects small splits
         same, # function: rejects similar splits
         epsilon): # small enough to split two parts
  """Looks for ways to split sorted data, 
  Recurses into each split. Assigns a 'rank' number
  to all the leaf splits found in this way. 
  """
  def recurse(parts,all,rank=0):
    "Split, then recurse on each part."
    cut,left,right = maybeIgnore(div(parts,all,big,epsilon),
                                 same,parts)
    if cut: 
      # if cut, rank "right" higher than "left"
      rank = recurse(parts[:cut],left,rank) + 1
      rank = recurse(parts[cut:],right,rank)
    else: 
      # if no cut, then all get same rank
      for part in parts: 
        part.rank = rank
    return rank
  recurse(sorted(data),all)
  return data

def maybeIgnore((cut,left,right), same,parts):
  if cut:
    if same(sum(parts[:cut],Num('upto')),
            sum(parts[cut:],Num('above'))):    
      cut = left = right = None
  return cut,left,right

def minMu(parts,all,big,epsilon):
  """Find a cut in the parts that maximizes
  the expected value of the difference in
  the mean before and after the cut.
  Reject splits that are insignificantly
  different or that generate very small subsets.
  """
  cut,left,right = None,None,None
  before, mu     =  0, all.mu
  for i,l,r in leftRight(parts,epsilon):
    if big(l.n) and big(r.n):
      n   = all.n * 1.0
      now = l.n/n*(mu- l.mu)**2 + r.n/n*(mu- r.mu)**2  
      if now > before:
        before,cut,left,right = now,i,l,r
  return cut,left,right

def leftRight(parts,epsilon=0.01):
  """Iterator. For all items in 'parts',
  return everything to the left and everything
  from here to the end. For reasons of
  efficiency, take a first pass over the data
  to pre-compute and cache right-hand-sides
  """
  rights = {}
  n = j = len(parts) - 1
  while j > 0:
    rights[j] = parts[j]
    if j < n: rights[j] += rights[j+1]
    j -=1
  left = parts[0]
  for i,one in enumerate(parts):
    if i> 0: 
      if parts[i]._median - parts[i-1]._median > epsilon:
        yield i,left,rights[i]
      left += one

bs=0
def bootstrap(y0,z0,conf=0.01,b=1000):
  """The bootstrap hypothesis test from
     p220 to 223 of Efron's book 'An
    introduction to the boostrap."""
  global bs
  bs += 1
  class total():
    "quick and dirty data collector"
    def __init__(i,some=[]):
      i.sum = i.n = i.mu = 0 ; i.all=[]
      for one in some: i.put(one)
    def put(i,x):
      i.all.append(x);
      i.sum +=x; i.n += 1; i.mu = float(i.sum)/i.n
    def __add__(i1,i2): return total(i1.all + i2.all)
  def testStatistic(y,z): 
    """Checks if two means are different, tempered
     by the sample size of 'y' and 'z'"""
    tmp1 = tmp2 = 0
    for y1 in y.all: tmp1 += (y1 - y.mu)**2 
    for z1 in z.all: tmp2 += (z1 - z.mu)**2
    s1    = (float(tmp1)/(y.n - 1))**0.5
    s2    = (float(tmp2)/(z.n - 1))**0.5
    delta = z.mu - y.mu
    if s1+s2:
      delta =  delta/((s1/y.n + s2/z.n)**0.5)
    return delta
  def one(lst): return lst[ int(any(len(lst))) ]
  def any(n)  : return random.uniform(0,n)
  y, z   = total(y0), total(z0)
  x      = y + z
  tobs   = testStatistic(y,z)
  yhat   = [y1 - y.mu + x.mu for y1 in y.all]
  zhat   = [z1 - z.mu + x.mu for z1 in z.all]
  bigger = 0.0
  for i in range(b):
    if testStatistic(total([one(yhat) for _ in yhat]),
                     total([one(zhat) for _ in zhat])) > tobs:
      bigger += 1
  return bigger / b < conf

def bootstrapd(): 
  def worker(n=30,mu1=10,sigma1=1,mu2=10.2,sigma2=1):
    def g(mu,sigma) : return random.gauss(mu,sigma)
    x = [g(mu1,sigma1) for i in range(n)]
    y = [g(mu2,sigma2) for i in range(n)]
    return n,mu1,sigma1,mu2,sigma2,\
        'different' if bootstrap(x,y) else 'same'
  print worker(30, 10.1, 1, 10.2, 1)
  print worker(30, 10.1, 1, 10.8, 1)
  print worker(30, 10.1, 10, 10.8, 1)
 

def rdivDemo(data,max=100):
  def z(x):
    return int(100 * (x - lo) / (hi - lo + 0.00001))
  data = map(lambda lst:Num(lst[0],lst[1:]),
             data)
  print ""
  ranks=[]
  for x in scottknott(data,useA12=True):
    ranks += [(x.rank,x.median(),x)]
  all=[]
  for _,__,x in sorted(ranks):
    all += x.quartiles()
  all = sorted(all)
  lo, hi = all[0], all[-1]
  print "{\\scriptsize \\begin{tabular}{l@{~~~}l@{~~~}r@{~~~}r@{~~~}c}"
  print "\\arrayrulecolor{darkgray}"
  print '\\rowcolor[gray]{.9}  rank & treatment & median & IQR & \\\\' #min= %s, max= %s\\\\' % (int(lo),int(hi))
  last = None
  for _,__,x in sorted(ranks):
    q1,q2,q3 = x.quartiles()
    pre =""
    if not last == None and not last == x.rank:
      pre= "\\hline"
    print pre,'%2s & %12s &    %s  &  %s & \quart{%s}{%s}{%s}{%s} \\\\' % \
        (x.rank+1, x.name, q2, q3 - q1, z(q1), z(q3) - z(q1), z(q2),z(100))
    last = x.rank 
  print "\\end{tabular}}"

def rdiv0():
  rdivDemo([
        ["x1",0.34, 0.49, 0.51, 0.6],
        ["x2",6,  7,  8,  9] ])

def rdiv1():
  rdivDemo([
        ["x1",0.1,  0.2,  0.3,  0.4],
        ["x2",0.1,  0.2,  0.3,  0.4],
        ["x3",6,  7,  8,  9] ])

def rdiv2():
  rdivDemo([
        ["x1",0.34, 0.49, 0.51, 0.6],
        ["x2",0.6,  0.7,  0.8,  0.9],
        ["x3",0.15, 0.25, 0.4,  0.35],
        ["x4",0.6,  0.7,  0.8,  0.9],
        ["x5",0.1,  0.2,  0.3,  0.4] ])

def rdiv3():
  rdivDemo([
      ["x1",101, 100, 99,   101,  99.5],
      ["x2",101, 100, 99,   101, 100],
      ["x3",101, 100, 99.5, 101,  99],
      ["x4",101, 100, 99,   101, 100] ])

def rdiv4():
  rdivDemo([
      ["1",11,12,13],
      ["2",14,31,22],
      ["3",23,24,31],
      ["5",32,33,34]])

def rdiv5():
  rdivDemo([
      ["1",11,11,11],
      ["2",11,11,11],
      ["3",11,11,11]])

def rdiv6():
  rdivDemo([
      ["1",11,11,11],
      ["2",11,11,11],
      ["4",32,33,34,35]])

#rdiv0(); rdiv1(); rdiv2(); rdiv3(); rdiv4(); rdiv5(); rdiv6()
#exit() 

def random_forest(repeat,exp,models,lst):
  repeats=10
  exp='locOrNot'
  models=[  'coc81',
            'nasa93']
  if len(sys.argv)>=2:
    repeats=eval(sys.argv[1])
  if len(sys.argv)>=3:
    exp=sys.argv[2]
  if len(sys.argv)>3:
    models=sys.argv[3:]

  print('''\documentclass{article}

  \usepackage{colortbl} % not sure if needed
  \usepackage[table]{xcolor} % not sure if needed

  %%%% needed %%%
  \usepackage{picture}
  \newcommand{\quart}[4]{\begin{picture}(100,6)%1
  {\color{black}\put(#3,3){\circle*{4}}\put(#1,3){\line(1,0){#2}}}\end{picture}}

  \begin{document}

  ''')

  test1(lst,repeats=repeats,models=map(eval,models),what=exp)

  print('''
  \end{document}
  ''')

class RandomForest(ModelBasic):
  def __init__(self,minR=-4,maxR=4,n=4,objf=1):
    self.minR=[2,2,100, 1]
    self.maxR=[32,32,3000, 25]
    self.n=n
    self.minVal=10000000
    self.maxVal=-1e6
    self.objf=objf
    self.past = [Log() for count in xrange(objf)]
    self.present = [Log() for count in xrange(objf)]
    self.lives=myModeloptions['Lives']
    self.functionDict = {}
    self.functionDict["f1"]="f1"


  def f1(self,listpoint,num=0):
    # convert = {de
    #            1 : 'auto',f chindea
    #            2 : 'sqrt',
    #            3 : 'log2'
    #           }
    repeats=1
    exp='locOrNot'
    models=['maxwell']
    assert(len(listpoint) == 4),"Wrong!"
    print listpoint
    msl = int(listpoint[1])
    y = int(listpoint[2])
    z = int(round(listpoint[3]))


    mss = int(listpoint[0])
    
    lst = [
                    ('forest(mss={},msl={},ne={},mf={})'.format(mss,msl,y,z),
                     Score(estimator_func=get_forest(min_samples_split=mss, min_samples_leaf=msl, 
                      n_estimators=y, max_features=z)))
                     
                  ]


    print "\n +==============================================="
    print lst
    retlst = test1(lst,repeats=1,models=map(eval,models),what=exp)
    print retlst
    print len(retlst)
    print int(len(retlst)/4 * 3)
    print int(len(retlst)/4)
    print "\nMedian: ", median(retlst)," IQR: ", (retlst[int(len(retlst)/4 * 3)] - retlst[int(len(retlst)/4)])
 
    print "- ===================================="
    #raise Exception("I am here")
    return median(retlst)#,retlst[len(retlst)/4] - retlst[len(retlst)*3/4]
 
  def info(self):
    return "Fonseca~"

  def baseline(self,minR,maxR):
    emin = 1e6
    emax = -1e6
    for x in range(0,90000):
      solution = [(self.minR[z] + random.random()*(self.maxR[z]-self.minR[z])) for z in range(0,self.n)]
      result=0
      for i in xrange(self.objf):
        temp="f"+str(i+1)
        callName = self.functionDict[temp]
        result+=float(getattr(self, callName)(solution,i+1))
      #self.returnMax(result)
      #self.returnMin(result)
      emin = emin if emin < result else result
      emax = emax if emax > result else result
    return emin,emax

